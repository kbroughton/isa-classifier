{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praetorian ML Challenge - explore data\n",
    "\n",
    "### This is the same as praet_ml_challenge notebook with a little more rough work included\n",
    "\n",
    "Notes:\n",
    "On https://p16.praetorian.com/blog/machine-learning-tutorial the link \"Machine Learning Binaries\" is broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "At first glance, this may seem like an unsupervised task, but since we can guess wrong and get the correct answer for a given challenge, we can build a supervised training set\n",
    "\n",
    "Inspecting a few ISA's for the supported architectures, it appears there are typically hundreds of instructions, not tens of thousands, so a non-sparse matrix approach might work fine for a first principles text embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overwriting etl.py\n"
     ]
    }
   ],
   "source": [
    "%%writefile etl.py\n",
    "\n",
    "from __future__ import print_function\n",
    "import base64\n",
    "import binascii\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "SUPPORTED_ARCHITECTURES = [\"avr\", \"alphaev56\", \"arm\", \"m68k\", \"mips\", \n",
    "                           \"mipsel\", \"powerpc\", \"s390\", \"sh4\", \"sparc\", \"x86_64\", \"xtensa\"]\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "\n",
    "class Server(object):\n",
    "    url = 'https://mlb.praetorian.com'\n",
    "    log = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.session = requests.session()\n",
    "        # in a sample of a few dozen, self.binary is either 32 or 36 bytes so pad X to 36 byte columns\n",
    "        self.binary  = None\n",
    "        self.hashes    = []\n",
    "        self.wins    = 0\n",
    "        self.targets = []\n",
    "        self.rate_limit_count = 0\n",
    "        self.unknown_server_exception_count = 0\n",
    "        self.retry_wait = 10\n",
    "        self.count = 0\n",
    "        self.failure_record = []\n",
    "        self.start_time = datetime.datetime.now()\n",
    "        self.response = None\n",
    "        self.email = None\n",
    "\n",
    "    def _request(self, route, method='get', data=None):\n",
    "        while True:\n",
    "            if self.count > 597:\n",
    "                print('Resetting session at count {}'.format(self.count))\n",
    "                self.session = requests.session()\n",
    "            try:\n",
    "                if method == 'get':\n",
    "                    r = self.session.get(self.url + route)\n",
    "                else:\n",
    "                    r = self.session.post(self.url + route, data=data)\n",
    "                self.status_code = r.status_code\n",
    "                if r.status_code == 429:\n",
    "                    self.rate_limit_count += 1\n",
    "                    self.failure_record.append({'type': 'rate_limit',\n",
    "                                                'count': self.count,\n",
    "                                                'time': (datetime.datetime.now() -\n",
    "                                                         self.start_time).total_seconds()})\n",
    "                    raise Exception('Rate Limit Exception')\n",
    "                if r.status_code == 500:\n",
    "                    self.unknown_server_exception_count += 1\n",
    "                    self.failure_record.append({'type': 'unknown_server_exception',\n",
    "                                                'count': self.count,\n",
    "                                                'time': (datetime.datetime.now() -\n",
    "                                                         self.start_time).total_seconds()})\n",
    "                    raise Exception('Unknown Server Exception')\n",
    "                self.response = r\n",
    "                return r.json()\n",
    "            except Exception as e:\n",
    "                self.log.error(e)\n",
    "                self.log.info('Waiting 60 seconds before next request')\n",
    "                time.sleep(60)\n",
    "                self.status_code = None\n",
    "\n",
    "    def get(self):\n",
    "        r = self._request(\"/challenge\")\n",
    "        self.targets = r.get('target', [])\n",
    "        # removed base64.base64decode(r.get('binary', '')) to keep raw data raw\n",
    "        self.binary  = r.get('binary', '')\n",
    "        return r\n",
    "\n",
    "    def post(self, target):\n",
    "        r = self._request(\"/solve\", method=\"post\", data={\"target\": target})\n",
    "        self.wins = r.get('correct', 0)\n",
    "        hash = r.get('hash', None)\n",
    "        if hash:\n",
    "            self.log.info(\"You win! {}\".format(hash))\n",
    "            self.collect_hash()\n",
    "        self.ans  = r.get('target', 'unknown')\n",
    "        return r\n",
    "    \n",
    "    def collect_hash(self):\n",
    "        r = self._request(\"/hash\", method=\"post\", data={\"email\": self.email})\n",
    "        hash = r.get('hash', None)\n",
    "        print('hash_response is {}'.format(r))\n",
    "        self.hashes.append(hash)\n",
    "        # reset the session to earn more hashes\n",
    "        self.session.close()\n",
    "        self.session = requests.session()\n",
    "        \n",
    "    def get_data(self, number=10000, model=None, email=None):\n",
    "        \"\"\"\n",
    "        Retrieves data in format\n",
    "        @param number: nubmer of samples to return\n",
    "        @returns {binary_data: values, targets: values, answers: values}\n",
    "        where binary_data = [ \"<base64 encoded string>\", ... ]\n",
    "        targets =  [ \"avr\", \"x86_64\", ... ]\n",
    "        answers = [one item from targets,]\n",
    "        \"\"\"\n",
    "        if email:\n",
    "            self.email = email\n",
    "            \n",
    "        data = {}\n",
    "        # If we grab a large data set make it a little more efficient by pre-allocating\n",
    "        data['binary_data'] = [None]*number\n",
    "        data['targets'] = [None]*number\n",
    "        data['answers'] = [None]*number\n",
    "        for i in range(number):\n",
    "            self.count = 0\n",
    "            self.get()\n",
    "            while((self.status_code != 200) and (self.count < MAX_RETRIES) ):\n",
    "                print('Status code != 200. Retrying')\n",
    "                self.count = self.count + 1\n",
    "                self.get()\n",
    "            data['binary_data'][i] = self.binary\n",
    "            data['targets'][i] = self.targets\n",
    "            if model:\n",
    "                X = hex_data([self.binary])\n",
    "                probs = model.predict_proba(X)    # array of shape [1,12]\n",
    "                targets = class_to_ones_hot_targets([self.targets], model.classes_.tolist())\n",
    "                #print('data', X)\n",
    "                #print('probs', probs)\n",
    "                #print('targets', targets)\n",
    "                guess_arch = guess_arch_name(model, X, targets)\n",
    "            else:\n",
    "                guess_arch = self.targets[0]\n",
    "            self.post(guess_arch)\n",
    "            while((self.status_code != 200) and (self.count < MAX_RETRIES) ):\n",
    "                print('post status code {}'.format(self.status_code))\n",
    "                self.count = self.count + 1\n",
    "                self.post(guess_arch)\n",
    "            #print(i, type(i), self.ans, X, type(data['answers']))\n",
    "            data['answers'][i] = self.ans\n",
    "            \n",
    "        return data\n",
    "    \n",
    "    def get_data_sets(self, num_train=1024, num_test=128, num_dev=128, model=None, email=None):\n",
    "        \"\"\"\n",
    "        @param model: If we have a trained model, make trained guesses while downloading data\n",
    "        \n",
    "        @returns {'train': {'binary_data': [num_train values],\n",
    "                            'targets': [num_train [6 values]],\n",
    "                            'answers': [num_train values],\n",
    "                  'dev': format as with 'train',\n",
    "                  'test': format as with 'train'\n",
    "        }\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        data['train'] = self.get_data(num_train, model=model, email=email)\n",
    "        data['dev'] = self.get_data(num_dev, model=model, email=email)\n",
    "        data['test'] = self.get_data(num_test, model=model, email=email)\n",
    "        return data\n",
    "        \n",
    "\n",
    "# We only use the server class for interacting with the api\n",
    "# The methods below can be used with stored data    \n",
    "\n",
    "        \n",
    "def store(data, root_dir=None):\n",
    "    \"\"\"\n",
    "    Store data to root_dir in a generated filename\n",
    "    \"\"\"\n",
    "    # extract some info from data to generate friendly part of filename\n",
    "    num_train = str(len(data['train']['answers']))\n",
    "    num_dev = str(len(data['dev']['answers']))\n",
    "    num_test = str(len(data['test']['answers']))\n",
    "    \n",
    "    if not root_dir:\n",
    "        root_dir = os.getcwd()\n",
    "    else:\n",
    "        root_dir = os.path.realpath(root_dir)\n",
    "    file_name = \"_\".join([num_train, num_dev, num_test, str(uuid.uuid1())[0:8]]) + \".json\"\n",
    "    file_path = os.path.join(root_dir, file_name)\n",
    "    \n",
    "    with open(file_path, 'w+') as f:\n",
    "        json.dump(data, f)\n",
    "            \n",
    "def load(path):\n",
    "    \"\"\"\n",
    "    load data from a single file.  Data must have format specified in get_data_sets        \n",
    "    \"\"\"\n",
    "    path = os.path.realpath(path)\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_dir(path):\n",
    "    \"\"\"\n",
    "    load data from an entire directory.  Data must have format specified in get_data_sets\n",
    "    \"\"\"\n",
    "    merged = {'train': { 'answers': [],\n",
    "                         'targets': [],\n",
    "                         'binary_data': [] },\n",
    "              'dev': { 'answers': [],\n",
    "                         'targets': [],\n",
    "                         'binary_data': [] },\n",
    "              'test': { 'answers': [],\n",
    "                         'targets': [],\n",
    "                         'binary_data': [] }\n",
    "             }\n",
    "    if os.path.isdir(path):\n",
    "        for root, dirs, filenames in os.walk(path, topdown=True):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith('.json'):\n",
    "                    merged = merge_data(merged, load(os.path.join(root, filename)))\n",
    "    else:\n",
    "        merged = load(os.path.abspath(path)\n",
    ")\n",
    "    return merged\n",
    "\n",
    "def merge_data(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Perform list additions for two identically formatted dicts with lists at depth 2\n",
    "    \"\"\"\n",
    "    #_dict1 = deepcopy(dict1)\n",
    "    for key in dict2:\n",
    "        assert(key in dict1)\n",
    "        for key2 in dict2[key]:\n",
    "            assert(key2 in dict2[key])\n",
    "            dict1[key][key2] = dict1[key][key2] + dict2[key][key2]\n",
    "    return dict1\n",
    "\n",
    "def hex_data(base64_binary_data, stride=1, expected_len=None):\n",
    "    \"\"\"\n",
    "    Take an list of base64 encoded data and convert to lists of hex characters\n",
    "    @params base64_binary_data: a base64 encoded string of (presumeably) 32 or 36 hex numbers\n",
    "                                shape = (m, 1)\n",
    "    @params stride: number of bytes to consider a word\n",
    "    @params expected_len: max length of hex array, used if we need to pad shorter arrays\n",
    "    @returns: np.array([map(hexlify,base64string),])\n",
    "              shape = (m, len(base64.b64decode(base64_binary_data))/stride)\n",
    "    \"\"\"\n",
    "    # Should check that we aren't discarding https://docs.python.org/2/library/base64.html\n",
    "    # Characters that are neither in the normal base-64 alphabet nor the\n",
    "    # alternative alphabet are discarded prior to the padding check.\n",
    "    # Only python2 version does checking and uses stride, expected_len as it was found\n",
    "    # that data was uniformly 0 misfits.\n",
    "    misfits = []\n",
    "    hex_X = []\n",
    "\n",
    "    for data in base64_binary_data:\n",
    "        data = base64.b64decode(data)\n",
    "\n",
    "        if sys.version_info > (3,0):\n",
    "            hex_X.append(binascii.hexlify(data).decode('utf-8'))\n",
    "        else:\n",
    "            byte_strings = []\n",
    "            for i in range(0, len(data) , stride):\n",
    "                byte_strings.append(data[i:i+stride])\n",
    "            # probably not needed for most text_embeddings, but since most seem 32 or 36 it might help\n",
    "            if expected_len:\n",
    "                delta = len(byte_strings) - expected_len\n",
    "                div = delta/stride\n",
    "                remainder = delta % stride\n",
    "                if remainder or (delta < 0):\n",
    "                    print('misfit data', byte_strings)\n",
    "                else:\n",
    "                    byte_strings.extend(['\\x00'*stride]*div)\n",
    "            hex_X.append([ binascii.hexlify(e) for e in byte_strings ])\n",
    "\n",
    "    return np.array(hex_X)\n",
    "\n",
    "def class_to_ones_hot_answers(answers, classes):\n",
    "    \"\"\"\n",
    "    Take an list of answers as strings and convert to array of ones hot\n",
    "    \n",
    "    @param answers: (m, 1) array of strings\n",
    "    @param classes: len(classes) array of strings\n",
    "    @returns: (m, len(classes)) array of 0s and 1s\n",
    "    \"\"\"\n",
    "    get_arch_index = np.vectorize(lambda x: classes.index(x))\n",
    "    answer_indices = get_arch_index(np.array(answers))\n",
    "    hots = np.zeros(shape=(len(answers),len(classes)))\n",
    "    hots[np.arange(len(answers)), answer_indices] = 1\n",
    "    return hots\n",
    "\n",
    "def class_to_ones_hot_targets(targets, classes):\n",
    "    \"\"\"\n",
    "    Take an list of targets as strings and convert to array of ones hot\n",
    "    \n",
    "    @param answers: (m, 1) array of strings\n",
    "    @param classes: len(classes) array of strings\n",
    "    @returns: (m, len(classes)) array of 0s and 1s\n",
    "    \"\"\"\n",
    "    get_arch_index = np.vectorize(lambda x: classes.index(x))\n",
    "    target_indices = get_arch_index(np.array(targets))\n",
    "    hots = np.zeros(shape=(len(targets),len(classes)))\n",
    "    # loop over the six columns of targets array\n",
    "    for idx in range(target_indices.shape[1]):\n",
    "        hots[np.arange(len(targets)), target_indices[:,idx]] = 1\n",
    "    return hots\n",
    "\n",
    "def class_to_ones_hot(answers, targets, classes):\n",
    "    \"\"\"\n",
    "    Converts lists to arrays and strings to ones-hot\n",
    "    \n",
    "    param answers: length m list of strings\n",
    "    param targets: length m list of [6 strings]\n",
    "    @returns (m, len(classes) answers, (m, len(classes) targets in ones-hot\n",
    "    \"\"\"\n",
    "    return class_to_ones_hot_answers(answers, classes), class_to_ones_hot_targets(targets, classes) \n",
    "\n",
    "\n",
    "def guess_arch_name(model, X, allowed_Y, use_targets=True):\n",
    "    \"\"\"\n",
    "    Get the arch name prediction from the probabilities in ones-hot\n",
    "    \n",
    "    model: model trained on (m, 1) input\n",
    "    X: numerical array of shape (m, 1)\n",
    "    targets: ones-hot array of shape (m, n_classes), ignored if use_targets = False\n",
    "    use_targets: if True, Improve our chances by taking the max over the possible targets (6 instead of 12)\n",
    "    \n",
    "    returns: (m, 1) of the most likely ISA arch names \n",
    "    \"\"\"\n",
    "    probs = model.predict_proba(X)\n",
    "    get_arch = np.vectorize(lambda x: model.classes_.__getitem__(x))\n",
    "    if use_targets:\n",
    "        return get_arch(np.argmax(probs*allowed_Y, axis=1))\n",
    "    else:\n",
    "        return get_arch(np.argmax(probs, axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/isa-classifier/sklearn\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /opt/conda/lib/python3.6/site-packages (from -r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /opt/conda/lib/python3.6/site-packages (from requests->-r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /opt/conda/lib/python3.6/site-packages (from requests->-r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /opt/conda/lib/python3.6/site-packages (from requests->-r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.6/site-packages (from requests->-r ../requirements.txt (line 1))\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch data while guessing with the model trained below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "# handy when developing etl in this notebook\n",
    "from importlib import reload\n",
    "if 'etl' in globals():\n",
    "    reload(etl)\n",
    "else:\n",
    "    import etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "s = etl.Server()\n",
    "data_set_new = s.get_data_sets(num_train=2048,\n",
    "                               num_test=256,\n",
    "                               num_dev=256,\n",
    "                               model=mnb_model,\n",
    "                               email='kesten.broughton@gmail.com')\n",
    "etl.store(data_set_new, '../ml_challenge/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'accuracy': 1.0, 'correct': 54, 'target': 'alphaev56'}"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fetch previously collected data on first run of this notebook\n",
    "Fetch some data in the format supplied by etl.py (train, dev, test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only run this cell the first time\n",
    "%cd ../\n",
    "!wget https://s3.us-east-2.amazonaws.com/isa-classifier/isa_classifier_data.tar.gz\n",
    "!tar xvf isa_classifier_data.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/projects/isa-classifier/sklearn\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024_128_128_eba414fa.json  2048_256_256_9e7a4848.json\r\n",
      "2048_256_256_075b60e8.json  2048_256_256_cb0707f0.json\r\n",
      "2048_256_256_0b966df8.json  2048_256_256_dd02089e.json\r\n",
      "2048_256_256_0baba5f4.json  2048_256_256_dd67c64e.json\r\n",
      "2048_256_256_2847388a.json  4096_512_512_6f9ef7d8.json\r\n",
      "2048_256_256_666e0b7e.json  4096_512_512_94537036.json\r\n",
      "2048_256_256_8f6606b2.json  512_128_128_76fe753c.json\r\n",
      "2048_256_256_98813c7c.json\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../ml_challenge\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load data for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "import etl\n",
    "\n",
    "data_set = etl.load_dir('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28160"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set['train']['binary_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_X_train[0:4] \n",
      " ['AADtjAAywX8ADD0gAADACQAA7AsAMuwMACj9gAIQPSAAAMAJAAD/jAAAQJ0ADMAfAAhIAAAQwZ8ACMAfAAzsDA==', 'AAb/////AAAAAAADbGx4CgAgAJgLAKkRwCAAmBuQkPWgmSDAIACZCMAgAJgrwCAAmQjBAADRAAChAACBAADgCA==', 'jIkAGI1LAACNaQAAAShIJK1pAACMSQAgJSkAARAA//GsSQAgjUIAAK+iABiMwgAIAAAwIYxCAACsogAMPAIAAA==', 'WDAwAFAwEACnSAAAWDDR4lBAEABYQNHeUEAQAFhAMABQQBAAWEAwBFBAEABYQNHaWDAwCFAwEABYMEAAUDAQAA==']\n",
      "orig_Y_train[0:4] \n",
      " ['powerpc', 'xtensa', 'mips', 's390']\n",
      "orig_train_targets[0:4] \n",
      " [['alphaev56', 'arm', 'powerpc', 's390', 'sh4', 'xtensa'], ['alphaev56', 'avr', 'mipsel', 'powerpc', 'sh4', 'xtensa'], ['avr', 'm68k', 'mips', 'powerpc', 'sh4', 'sparc'], ['arm', 'avr', 'm68k', 'mips', 'mipsel', 's390']]\n"
     ]
    }
   ],
   "source": [
    "orig_X_train, orig_Y_train, orig_train_targets = data_set['train']['binary_data'], data_set['train']['answers'], data_set['train']['targets']\n",
    "orig_X_dev, orig_Y_dev, orig_dev_targets = data_set['dev']['binary_data'], data_set['dev']['answers'], data_set['dev']['targets']\n",
    "orig_X_test, orig_Y_test, orig_test_targets = data_set['test']['binary_data'], data_set['test']['answers'], data_set['test']['targets']\n",
    "\n",
    "print('orig_X_train[0:4]', '\\n', orig_X_train[0:4])\n",
    "print('orig_Y_train[0:4]', '\\n', orig_Y_train[0:4])\n",
    "print('orig_train_targets[0:4]', '\\n', orig_train_targets[0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hex_X_train[0:4] [ '0000ed8c0032c17f000c3d200000c0090000ec0b0032ec0c0028fd8002103d200000c0090000ff8c0000409d000cc01f000848000010c19f0008c01f000cec0c'\n",
      " '0006ffffffff0000000000036c6c780a002000980b00a911c02000981b9090f5a09920c020009908c02000982bc020009908c10000d10000a10000810000e008'\n",
      " '8c8900188d4b00008d69000001284824ad6900008c490020252900011000fff1ac4900208d420000afa200188cc20008000030218c420000aca2000c3c020000'\n",
      " '5830300050301000a74800005830d1e2504010005840d1de50401000584030005040100058403004504010005840d1da58303008503010005830400050301000'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hex_X_train = etl.hex_data(orig_X_train)\n",
    "hex_X_dev = etl.hex_data(orig_X_dev)\n",
    "hex_X_test = etl.hex_data(orig_X_test)\n",
    "\n",
    "print('hex_X_train[0:4]', hex_X_train[0:4], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "idf_opts = {\n",
    "    \"ngram_range\": (1, 6),  # allow n-grams of 1-6 words in length (32-bits)\n",
    "    \"analyzer\": \"word\",     # analyze hex words\n",
    "    \"token_pattern\": \"..\",  # treat two characters as a word (e.g. 4b)\n",
    "    \"min_df\": 2,          # for demo purposes, be very selective about features\n",
    "    \"max_df\": .7\n",
    "}\n",
    "\n",
    "pipeline = Pipeline(steps=[\n",
    "    ('idf',  TfidfVectorizer(**idf_opts)),\n",
    "    ('mnb_classifier', MultinomialNB(alpha=1e-4))\n",
    "])\n",
    "\n",
    "mnb_model = pipeline.fit(hex_X_train, orig_Y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### express correct arch and targets in ones-hot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train[0:4] \n",
      " [[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]] \n",
      "\n",
      "allowed_Y_train[0:4] \n",
      " [[1 1 0 0 0 0 1 1 1 0 0 1]\n",
      " [1 0 1 0 0 1 1 0 1 0 0 1]\n",
      " [0 0 1 1 1 0 1 0 1 1 0 0]\n",
      " [0 1 1 1 1 1 0 1 0 0 0 0]] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_train, allowed_Y_train = class_to_ones_hot(orig_Y_train, orig_train_targets, mnb_model.classes_.tolist())\n",
    "Y_dev, allowed_Y_dev = class_to_ones_hot(orig_Y_dev, orig_dev_targets, mnb_model.classes_.tolist())\n",
    "Y_test, allowed_Y_test = class_to_ones_hot(orig_Y_test, orig_test_targets, mnb_model.classes_.tolist())\n",
    "\n",
    "print('Y_train[0:4]', '\\n', Y_train[0:4], '\\n')\n",
    "print('allowed_Y_train[0:4]', '\\n', allowed_Y_train[0:4], '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_ones_hot_answers(orig_Y_train[0:4], mnb_model.classes_.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa =  [[ 0  1  6  7  8 11]\n",
      " [ 0  2  5  6  8 11]\n",
      " [ 2  3  4  6  8  9]\n",
      " [ 1  2  3  4  5  7]]\n",
      "[[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n",
      " [ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.]]\n"
     ]
    }
   ],
   "source": [
    "aa = get_arch_index(np.array(orig_train_targets[0:4]))\n",
    "print('aa = ', aa)\n",
    "bb = np.zeros(shape=(len(aa),len(mnb_model.classes_.tolist())))\n",
    "print(bb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alphaev56', 'arm', 'avr', 'm68k', 'mips', 'mipsel', 'powerpc', 's390', 'sh4', 'sparc', 'x86_64', 'xtensa']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([ 6, 11,  4,  7])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classes = mnb_model.classes_.tolist()\n",
    "print(classes)\n",
    "get_arch_index = np.vectorize(lambda x: classes.index(x))\n",
    "get_arch_index(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.arange(aa.size + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 2, 1])"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aa[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 1.,  1.,  0.,  0.,  0.,  0.,  1.,  1.,  1.,  0.,  0.,  1.],\n",
       "       [ 1.,  0.,  1.,  0.,  0.,  1.,  1.,  0.,  1.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  1.,  1.,  1.,  0.,  1.,  0.,  1.,  1.,  0.,  0.],\n",
       "       [ 0.,  1.,  1.,  1.,  1.,  1.,  0.,  1.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class_to_ones_hot_targets(orig_train_targets[0:4], mnb_model.classes_.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'idf': TfidfVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
       "         dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
       "         lowercase=True, max_df=0.7, max_features=None, min_df=2,\n",
       "         ngram_range=(1, 6), norm='l2', preprocessor=None, smooth_idf=True,\n",
       "         stop_words=None, strip_accents=None, sublinear_tf=False,\n",
       "         token_pattern='..', tokenizer=None, use_idf=True, vocabulary=None),\n",
       " 'mnb_classifier': MultinomialNB(alpha=0.0001, class_prior=None, fit_prior=True)}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model.named_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('ed', 453681), ('8c', 348571), ('32', 231413), ('c1', 406009), ('7f', 319670), ('0c', 134567), ('3d', 244282), ('20', 178005), ('c0', 401316), ('09', 127622)]\n",
      "479442\n"
     ]
    }
   ],
   "source": [
    "print(list(mnb_model.named_steps['idf'].vocabulary_.items())[0:10])\n",
    "print(len(mnb_model.named_steps['idf'].vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['alphaev56', 'arm', 'avr', 'm68k', 'mips', 'mipsel', 'powerpc', 's390', 'sh4', 'sparc', 'x86_64', 'xtensa']\n"
     ]
    }
   ],
   "source": [
    "print(mnb_model.classes_.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw probs\n",
      "[[  3.72529819e-56   8.52298124e-55   6.59767442e-58   3.45827128e-54\n",
      "    4.34330560e-55   7.13731395e-54   1.00000000e+00   2.06216067e-56\n",
      "    1.07588823e-54   1.12221014e-56   4.16804670e-55   2.73407500e-53]\n",
      " [  9.00436743e-54   3.77972145e-51   1.40041144e-56   1.48851541e-49\n",
      "    2.83634097e-49   4.65771836e-52   2.52573900e-50   1.19737549e-52\n",
      "    5.74658109e-51   9.22122859e-52   3.20994174e-52   1.00000000e+00]\n",
      " [  7.03684698e-39   3.87522477e-40   2.85878253e-43   2.43445701e-38\n",
      "    1.00000000e+00   6.98965433e-37   2.01446542e-37   1.25472653e-40\n",
      "    4.18878549e-38   4.42189820e-42   1.80117947e-37   1.01820641e-38]\n",
      " [  2.59655045e-46   4.09984989e-45   2.36775114e-49   2.27121054e-46\n",
      "    6.65832437e-45   2.46876807e-45   1.17045622e-46   1.00000000e+00\n",
      "    1.77021255e-46   9.59116322e-50   1.85863618e-49   1.27250164e-47]]\n",
      "allowed probs\n",
      "[[  3.72529819e-56   8.52298124e-55   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   2.06216067e-56\n",
      "    1.07588823e-54   0.00000000e+00   0.00000000e+00   2.73407500e-53]\n",
      " [  9.00436743e-54   0.00000000e+00   1.40041144e-56   0.00000000e+00\n",
      "    0.00000000e+00   4.65771836e-52   2.52573900e-50   0.00000000e+00\n",
      "    5.74658109e-51   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "allowed\n",
      "[[1 1 0 0 0 0 1 1 1 0 0 1]\n",
      " [1 0 1 0 0 1 1 0 1 0 0 1]]\n",
      "[ 6 11]\n",
      "['powerpc', 'xtensa', 'mips', 's390', 's390', 'alphaev56', 'alphaev56', 'x86_64', 'powerpc', 'mips']\n",
      "correct\n",
      "['powerpc', 'xtensa', 'mips', 's390', 's390', 'alphaev56', 'alphaev56', 'x86_64', 'powerpc', 'mips']\n",
      "[[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "probs_train = mnb_model.predict_proba(hex_X_train)\n",
    "print(\"raw probs\")\n",
    "print(probs_train[0:4])\n",
    "print(\"allowed probs\")\n",
    "print(probs_train[0:2]*allowed_Y_train[0:2])\n",
    "print(\"allowed\")\n",
    "print(allowed_Y_train[0:2])\n",
    "print(np.argmax(probs_train[0:2]*allowed_Y_train[0:2], axis=1))\n",
    "print(list(map(mnb_model.classes_.tolist().__getitem__, np.argmax(probs_train[0:10]*allowed_Y_train[0:10], axis=1))))\n",
    "print(\"correct\")\n",
    "print(orig_Y_train[0:10])\n",
    "print(Y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "guess_train = guess_arch_name(mnb_model, hex_X_train, allowed_Y_train, use_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('powerpc', 'powerpc')"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "guess_train[0], orig_Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>28160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x86_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2478</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             0\n",
       "count    28160\n",
       "unique      12\n",
       "top     x86_64\n",
       "freq      2478"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = pd.DataFrame(guess_train)\n",
    "D.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = pd.Series(orig_Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "x86_64       2476\n",
       "alphaev56    2404\n",
       "powerpc      2389\n",
       "arm          2386\n",
       "avr          2382\n",
       "xtensa       2358\n",
       "sh4          2347\n",
       "s390         2346\n",
       "sparc        2309\n",
       "mipsel       2305\n",
       "m68k         2244\n",
       "mips         2214\n",
       "dtype: int64"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a pretty good distribution of classes < 10% variance in counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_results(predictions, orig_Y):\n",
    "    wrong = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != orig_Y[i]:\n",
    "            wrong.append([predictions[i], orig_Y[i]])\n",
    "    print('training error: {}%'.format(100.0*len(wrong)/len(predictions)))\n",
    "    print('some mistakes')\n",
    "    print(wrong[0:15])\n",
    "    return wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.01775568181818182%\n",
      "some mistakes\n",
      "[['m68k', 'powerpc'], ['x86_64', 'powerpc'], ['m68k', 'sparc'], ['m68k', 'powerpc'], ['x86_64', 'sh4']]\n"
     ]
    }
   ],
   "source": [
    "wrong = describe_results(guess_train, orig_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m68k</td>\n",
       "      <td>powerpc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incorrect  correct\n",
       "count          5        5\n",
       "unique         2        3\n",
       "top         m68k  powerpc\n",
       "freq           3        3"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw = pd.DataFrame(wrong)\n",
    "pdw.columns = ['incorrect', 'correct']\n",
    "pdw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">powerpc</th>\n",
       "      <th>count</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m68k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">sh4</th>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x86_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">sparc</th>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m68k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               incorrect\n",
       "correct                 \n",
       "powerpc count          3\n",
       "        unique         2\n",
       "        top         m68k\n",
       "        freq           2\n",
       "sh4     count          1\n",
       "        unique         1\n",
       "        top       x86_64\n",
       "        freq           1\n",
       "sparc   count          1\n",
       "        unique         1\n",
       "        top         m68k\n",
       "        freq           1"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw.groupby(by=pdw.correct).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model is worst at predicting powerpc, then sh4 and sparc\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incorrect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">m68k</th>\n",
       "      <th>count</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>powerpc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">x86_64</th>\n",
       "      <th>count</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sh4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  correct\n",
       "incorrect                \n",
       "m68k      count         3\n",
       "          unique        2\n",
       "          top     powerpc\n",
       "          freq          2\n",
       "x86_64    count         2\n",
       "          unique        2\n",
       "          top         sh4\n",
       "          freq          1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw.groupby(by=pdw.incorrect).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m68k</td>\n",
       "      <td>powerpc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m68k</td>\n",
       "      <td>sparc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m68k</td>\n",
       "      <td>powerpc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incorrect  correct\n",
       "0      m68k  powerpc\n",
       "2      m68k    sparc\n",
       "3      m68k  powerpc"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most false positives come from x86_64 and m68k, we are slightly over-fitting to them\n",
    "pdw[pdw.incorrect == 'm68k'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m68k</td>\n",
       "      <td>powerpc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>x86_64</td>\n",
       "      <td>powerpc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m68k</td>\n",
       "      <td>sparc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m68k</td>\n",
       "      <td>powerpc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>x86_64</td>\n",
       "      <td>sh4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incorrect  correct\n",
       "0      m68k  powerpc\n",
       "1    x86_64  powerpc\n",
       "2      m68k    sparc\n",
       "3      m68k  powerpc\n",
       "4    x86_64      sh4"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m68k</td>\n",
       "      <td>sparc</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incorrect correct\n",
       "2      m68k   sparc"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw[pdw.correct == 'sparc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat for dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3584 3584\n",
      "[  7.81860230e-23   1.08365283e-22   6.08540843e-24   2.04919912e-20\n",
      "   3.07761872e-22   5.78563323e-24   1.00000000e+00   2.41413288e-24\n",
      "   1.59244396e-20   6.62849794e-24   1.00722378e-20   1.08299070e-22] [1 0 0 1 0 0 1 1 1 0 1 0] ['alphaev56', 'm68k', 'powerpc', 's390', 'sh4', 'x86_64']\n"
     ]
    }
   ],
   "source": [
    "probs_dev = mnb_model.predict_proba(hex_X_dev)\n",
    "\n",
    "print(len(probs_dev), len(allowed_Y_dev))\n",
    "print(probs_dev[0], allowed_Y_dev[0], orig_dev_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dev = guess_arch_name(mnb_model, hex_X_dev, allowed_Y_dev, use_targets=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.3627232142857143%\n",
      "some mistakes\n",
      "[['x86_64', 'sh4'], ['sh4', 'mipsel'], ['x86_64', 'sh4'], ['m68k', 'avr'], ['s390', 'sparc'], ['x86_64', 'm68k'], ['alphaev56', 'mipsel'], ['sh4', 'mipsel'], ['m68k', 'powerpc'], ['m68k', 'xtensa'], ['x86_64', 'arm'], ['x86_64', 'xtensa'], ['xtensa', 's390']]\n"
     ]
    }
   ],
   "source": [
    "wrong_dev = describe_results(predictions_dev, orig_Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9946986607142857"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model.score(hex_X_dev, orig_Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x86_64</td>\n",
       "      <td>mipsel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incorrect correct\n",
       "count         13      13\n",
       "unique         6       9\n",
       "top       x86_64  mipsel\n",
       "freq           5       3"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw = pd.DataFrame(wrong_dev)\n",
    "pdw.columns = ['incorrect', 'correct']\n",
    "pdw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">arm</th>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x86_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">avr</th>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m68k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">m68k</th>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x86_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">mipsel</th>\n",
       "      <th>count</th>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>sh4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">powerpc</th>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m68k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">s390</th>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>xtensa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">sh4</th>\n",
       "      <th>count</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x86_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">sparc</th>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>s390</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th rowspan=\"4\" valign=\"top\">xtensa</th>\n",
       "      <th>count</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>x86_64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               incorrect\n",
       "correct                 \n",
       "arm     count          1\n",
       "        unique         1\n",
       "        top       x86_64\n",
       "        freq           1\n",
       "avr     count          1\n",
       "        unique         1\n",
       "        top         m68k\n",
       "        freq           1\n",
       "m68k    count          1\n",
       "        unique         1\n",
       "        top       x86_64\n",
       "        freq           1\n",
       "mipsel  count          3\n",
       "        unique         2\n",
       "        top          sh4\n",
       "        freq           2\n",
       "powerpc count          1\n",
       "        unique         1\n",
       "        top         m68k\n",
       "        freq           1\n",
       "s390    count          1\n",
       "        unique         1\n",
       "        top       xtensa\n",
       "        freq           1\n",
       "sh4     count          2\n",
       "        unique         1\n",
       "        top       x86_64\n",
       "        freq           2\n",
       "sparc   count          1\n",
       "        unique         1\n",
       "        top         s390\n",
       "        freq           1\n",
       "xtensa  count          2\n",
       "        unique         2\n",
       "        top       x86_64\n",
       "        freq           1"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw.groupby(by=pdw.correct).describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_decomposition/pls_.py:83: UserWarning: Maximum number of iterations reached\n",
      "  warnings.warn('Maximum number of iterations reached')\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_decomposition/pls_.py:293: UserWarning: Y residual constant at iteration 11\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bad input shape (12, 4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-70ddcd13f8df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mX_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mplot_subfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"With unlabeled samples + CCA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cca\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mplot_subfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"With unlabeled samples + PCA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pca\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-70ddcd13f8df>\u001b[0m in \u001b[0;36mplot_subfigure\u001b[0;34m(X, Y, subplot, title, transform)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclassif\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mclassif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    524\u001b[0m                         dtype=None)\n\u001b[1;32m    525\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (12, 4096)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "\n",
    "def plot_hyperplane(clf, min_x, max_x, linestyle, label):\n",
    "    # get the separating hyperplane\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(min_x - 5, max_x + 5)  # make sure the line is long enough\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "    plt.plot(xx, yy, linestyle, label=label)\n",
    "\n",
    "\n",
    "def plot_subfigure(X, Y, subplot, title, transform):\n",
    "    if transform == \"pca\":\n",
    "        X = PCA(n_components=12).fit_transform(X)\n",
    "    elif transform == \"cca\":\n",
    "        X = CCA(n_components=12).fit(X, Y_train).transform(X)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "\n",
    "    classif = SVC(kernel='linear')\n",
    "    classif.fit(X, Y_train.transpose())\n",
    "\n",
    "    plt.subplot(2, 2, subplot)\n",
    "    plt.title(title)\n",
    "\n",
    "    zero_class = np.where(Y_train[:, 0])\n",
    "    one_class = np.where(Y_train[:, 1])\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=40, c='gray', edgecolors=(0, 0, 0))\n",
    "    plt.scatter(X[zero_class, 0], X[zero_class, 1], s=160, edgecolors='b',\n",
    "                facecolors='none', linewidths=2, label='Class 1')\n",
    "    plt.scatter(X[one_class, 0], X[one_class, 1], s=80, edgecolors='orange',\n",
    "                facecolors='none', linewidths=2, label='Class 2')\n",
    "\n",
    "    plot_hyperplane(classif.estimators_[0], min_x, max_x, 'k--',\n",
    "                    'Boundary\\nfor class 1')\n",
    "    plot_hyperplane(classif.estimators_[1], min_x, max_x, 'k-.',\n",
    "                    'Boundary\\nfor class 2')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.xlim(min_x - .5 * max_x, max_x + .5 * max_x)\n",
    "    plt.ylim(min_y - .5 * max_y, max_y + .5 * max_y)\n",
    "    if subplot == 2:\n",
    "        plt.xlabel('First principal component')\n",
    "        plt.ylabel('Second principal component')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# X, Y = make_multilabel_classification(n_classes=2, n_labels=1,\n",
    "#                                       allow_unlabeled=True,\n",
    "#                                       random_state=1)\n",
    "X_arr = X.toarray()\n",
    "\n",
    "plot_subfigure(X_arr, Y_train, 1, \"With unlabeled samples + CCA\", \"cca\")\n",
    "plot_subfigure(X_arr, Y, 2, \"With unlabeled samples + PCA\", \"pca\")\n",
    "\n",
    "# X, Y = make_multilabel_classification(n_classes=2, n_labels=1,\n",
    "#                                       allow_unlabeled=False,\n",
    "#                                       random_state=1)\n",
    "\n",
    "# plot_subfigure(X, Y, 3, \"Without unlabeled samples + CCA\", \"cca\")\n",
    "# plot_subfigure(X, Y, 4, \"Without unlabeled samples + PCA\", \"pca\")\n",
    "\n",
    "plt.subplots_adjust(.04, .02, .97, .94, .09, .2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt, Yt = make_multilabel_classification(n_classes=12, n_labels=1,\n",
    "                                      allow_unlabeled=True,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yt[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20) (100, 12)\n"
     ]
    }
   ],
   "source": [
    "print(Xt.shape, Yt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print Y.shape\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
