{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# multi-classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "based on http://scikit-learn.org/stable/auto_examples/text/document_classification_20newsgroups.html\n",
    "\n",
    "Explore different classifiers on our isa dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First let's run the original example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --report              Print a detailed classification report.\n",
      "  --chi2_select=SELECT_CHI2\n",
      "                        Select some number of features using a chi-squared\n",
      "                        test\n",
      "  --confusion_matrix    Print the confusion matrix.\n",
      "  --top10               Print ten most discriminative terms per class for\n",
      "                        every classifier.\n",
      "  --all_categories      Whether to use all categories or not.\n",
      "  --use_hashing         Use a hashing vectorizer.\n",
      "  --n_features=N_FEATURES\n",
      "                        n_features when using the hashing vectorizer.\n",
      "  --filtered            Remove newsgroup information that is easily overfit:\n",
      "                        headers, signatures, and quoting.\n",
      "\n",
      "Loading 20 newsgroups dataset for categories:\n",
      "['alt.atheism', 'talk.religion.misc', 'comp.graphics', 'sci.space']\n",
      "data loaded\n",
      "2034 documents - 3.980MB (training set)\n",
      "1353 documents - 2.867MB (test set)\n",
      "4 categories\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n",
      "done in 0.890658s at 4.468MB/s\n",
      "n_samples: 2034, n_features: 33809\n",
      "\n",
      "Extracting features from the test data using the same vectorizer\n",
      "done in 0.447884s at 6.402MB/s\n",
      "n_samples: 1353, n_features: 33809\n",
      "\n",
      "================================================================================\n",
      "Ridge Classifier\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,\n",
      "        max_iter=None, normalize=False, random_state=None, solver='lsqr',\n",
      "        tol=0.01)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/sklearn/linear_model/ridge.py:311: UserWarning: In Ridge, only 'sag' solver can currently fit the intercept when X is sparse. Solver has been automatically changed into 'sag'.\n",
      "  warnings.warn(\"In Ridge, only 'sag' solver can currently fit the \"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 0.462s\n",
      "test time:  0.002s\n",
      "accuracy:   0.897\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Perceptron\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Perceptron(alpha=0.0001, class_weight=None, eta0=1.0, fit_intercept=True,\n",
      "      n_iter=50, n_jobs=1, penalty=None, random_state=0, shuffle=True,\n",
      "      verbose=0, warm_start=False)\n",
      "train time: 0.193s\n",
      "test time:  0.006s\n",
      "accuracy:   0.885\n",
      "dimensionality: 33809\n",
      "density: 0.240165\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Passive-Aggressive\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "PassiveAggressiveClassifier(C=1.0, class_weight=None, fit_intercept=True,\n",
      "              loss='hinge', n_iter=50, n_jobs=1, random_state=None,\n",
      "              shuffle=True, verbose=0, warm_start=False)\n",
      "train time: 0.170s\n",
      "test time:  0.003s\n",
      "accuracy:   0.902\n",
      "dimensionality: 33809\n",
      "density: 0.701307\n",
      "\n",
      "\n",
      "================================================================================\n",
      "kNN\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n",
      "           metric_params=None, n_jobs=1, n_neighbors=10, p=2,\n",
      "           weights='uniform')\n",
      "train time: 0.001s\n",
      "test time:  0.470s\n",
      "accuracy:   0.858\n",
      "\n",
      "================================================================================\n",
      "Random forest\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
      "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
      "            min_impurity_split=1e-07, min_samples_leaf=1,\n",
      "            min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
      "            n_estimators=100, n_jobs=1, oob_score=False, random_state=None,\n",
      "            verbose=0, warm_start=False)\n",
      "train time: 2.309s\n",
      "test time:  0.136s\n",
      "accuracy:   0.823\n",
      "\n",
      "================================================================================\n",
      "L2 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.127s\n",
      "test time:  0.002s\n",
      "accuracy:   0.900\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l2', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.127s\n",
      "test time:  0.002s\n",
      "accuracy:   0.900\n",
      "dimensionality: 33809\n",
      "density: 0.665977\n",
      "\n",
      "\n",
      "================================================================================\n",
      "L1 penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0)\n",
      "train time: 0.285s\n",
      "test time:  0.002s\n",
      "accuracy:   0.873\n",
      "dimensionality: 33809\n",
      "density: 0.005553\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='l1', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.415s\n",
      "test time:  0.002s\n",
      "accuracy:   0.887\n",
      "dimensionality: 33809\n",
      "density: 0.020253\n",
      "\n",
      "\n",
      "================================================================================\n",
      "Elastic-Net penalty\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "SGDClassifier(alpha=0.0001, average=False, class_weight=None, epsilon=0.1,\n",
      "       eta0=0.0, fit_intercept=True, l1_ratio=0.15,\n",
      "       learning_rate='optimal', loss='hinge', n_iter=50, n_jobs=1,\n",
      "       penalty='elasticnet', power_t=0.5, random_state=None, shuffle=True,\n",
      "       verbose=0, warm_start=False)\n",
      "train time: 0.609s\n",
      "test time:  0.002s\n",
      "accuracy:   0.899\n",
      "dimensionality: 33809\n",
      "density: 0.187864\n",
      "\n",
      "\n",
      "================================================================================\n",
      "NearestCentroid (aka Rocchio classifier)\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "NearestCentroid(metric='euclidean', shrink_threshold=None)\n",
      "train time: 0.017s\n",
      "test time:  0.003s\n",
      "accuracy:   0.855\n",
      "\n",
      "================================================================================\n",
      "Naive Bayes\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)\n",
      "train time: 0.007s\n",
      "test time:  0.002s\n",
      "accuracy:   0.899\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "BernoulliNB(alpha=0.01, binarize=0.0, class_prior=None, fit_prior=True)\n",
      "train time: 0.008s\n",
      "test time:  0.008s\n",
      "accuracy:   0.884\n",
      "dimensionality: 33809\n",
      "density: 1.000000\n",
      "\n",
      "\n",
      "================================================================================\n",
      "LinearSVC with L1-based feature selection\n",
      "________________________________________________________________________________\n",
      "Training: \n",
      "Pipeline(steps=[('feature_selection', SelectFromModel(estimator=LinearSVC(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
      "     intercept_scaling=1, loss='squared_hinge', max_iter=1000,\n",
      "     multi_class='ovr', penalty='l1', random_state=None, tol=0.001,\n",
      "     verbose=0),\n",
      "        prefit=False, thresho...ax_iter=1000,\n",
      "     multi_class='ovr', penalty='l2', random_state=None, tol=0.0001,\n",
      "     verbose=0))])\n",
      "train time: 0.298s\n",
      "test time:  0.004s\n",
      "accuracy:   0.880\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fea7e3341d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--report\",\n",
    "              action=\"store_true\", dest=\"print_report\",\n",
    "              help=\"Print a detailed classification report.\")\n",
    "op.add_option(\"--chi2_select\",\n",
    "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
    "              help=\"Select some number of features using a chi-squared test\")\n",
    "op.add_option(\"--confusion_matrix\",\n",
    "              action=\"store_true\", dest=\"print_cm\",\n",
    "              help=\"Print the confusion matrix.\")\n",
    "op.add_option(\"--top10\",\n",
    "              action=\"store_true\", dest=\"print_top10\",\n",
    "              help=\"Print ten most discriminative terms per class\"\n",
    "                   \" for every classifier.\")\n",
    "op.add_option(\"--all_categories\",\n",
    "              action=\"store_true\", dest=\"all_categories\",\n",
    "              help=\"Whether to use all categories or not.\")\n",
    "op.add_option(\"--use_hashing\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Use a hashing vectorizer.\")\n",
    "op.add_option(\"--n_features\",\n",
    "              action=\"store\", type=int, default=2 ** 16,\n",
    "              help=\"n_features when using the hashing vectorizer.\")\n",
    "op.add_option(\"--filtered\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Remove newsgroup information that is easily overfit: \"\n",
    "                   \"headers, signatures, and quoting.\")\n",
    "\n",
    "\n",
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')\n",
    "\n",
    "# work-around for Jupyter notebook and IPython console\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "print()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Load some categories from the training set\n",
    "if opts.all_categories:\n",
    "    categories = None\n",
    "else:\n",
    "    categories = [\n",
    "        'alt.atheism',\n",
    "        'talk.religion.misc',\n",
    "        'comp.graphics',\n",
    "        'sci.space',\n",
    "    ]\n",
    "\n",
    "if opts.filtered:\n",
    "    remove = ('headers', 'footers', 'quotes')\n",
    "else:\n",
    "    remove = ()\n",
    "\n",
    "print(\"Loading 20 newsgroups dataset for categories:\")\n",
    "print(categories if categories else \"all\")\n",
    "\n",
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                                shuffle=True, random_state=42,\n",
    "                                remove=remove)\n",
    "\n",
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               shuffle=True, random_state=42,\n",
    "                               remove=remove)\n",
    "print('data loaded')\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = data_train.target_names\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s.encode('utf-8')) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(data_train.data)\n",
    "data_test_size_mb = size_mb(data_test.data)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(data_train.data), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (test set)\" % (\n",
    "    len(data_test.data), data_test_size_mb))\n",
    "print(\"%d categories\" % len(categories))\n",
    "print()\n",
    "\n",
    "# split a training set and a test set\n",
    "y_train, y_test = data_train.target, data_test.target\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', alternate_sign=False,\n",
    "                                   n_features=opts.n_features)\n",
    "    X_train = vectorizer.transform(data_train.data)\n",
    "else:\n",
    "    vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                                 stop_words='english')\n",
    "    X_train = vectorizer.fit_transform(data_train.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "X_test = vectorizer.transform(data_test.data)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "if opts.use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "if opts.select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "          opts.select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names:\n",
    "        # keep selected feature names\n",
    "        feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf):\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3)))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty)))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\")))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid()))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01)))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01)))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))])))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following cell pulls down large datasets from fetch_20newsgroups.\n",
    "# Skip if you don't need to compare with our use case"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### See what data format it expects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"From: rych@festival.ed.ac.uk (R Hawkes)\\nSubject: 3DS: Where did all the texture rules go?\\nLines: 21\\n\\nHi,\\n\\nI've noticed that if you only save a model (with all your mapping planes\\npositioned carefully) to a .3DS file that when you reload it after restarting\\n3DS, they are given a default position and orientation.  But if you save\\nto a .PRJ file their positions/orientation are preserved.  Does anyone\\nknow why this information is not stored in the .3DS file?  Nothing is\\nexplicitly said in the manual about saving texture rules in the .PRJ file. \\nI'd like to be able to read the texture rule information, does anyone have \\nthe format for the .PRJ file?\\n\\nIs the .CEL file format available from somewhere?\\n\\nRych\\n\\n======================================================================\\nRycharde Hawkes\\t\\t\\t\\temail: rych@festival.ed.ac.uk\\nVirtual Environment Laboratory\\nDept. of Psychology\\t\\t\\tTel  : +44 31 650 3426\\nUniv. of Edinburgh\\t\\t\\tFax  : +44 31 667 0150\\n======================================================================\\n\",\n",
       " \"Subject: Re: Biblical Backing of Koresh's 3-02 Tape (Cites enclosed)\\nFrom: kmcvay@oneb.almanac.bc.ca (Ken Mcvay)\\nOrganization: The Old Frog's Almanac\\nLines: 20\\n\\nIn article <20APR199301460499@utarlg.uta.edu> b645zaw@utarlg.uta.edu (stephen) writes:\\n\\n>Seems to me Koresh is yet another messenger that got killed\\n>for the message he carried. (Which says nothing about the \\n\\nSeems to be, barring evidence to the contrary, that Koresh was simply\\nanother deranged fanatic who thought it neccessary to take a whole bunch of\\nfolks with him, children and all, to satisfy his delusional mania. Jim\\nJones, circa 1993.\\n\\n>In the mean time, we sure learned a lot about evil and corruption.\\n>Are you surprised things have gotten that rotten?\\n\\nNope - fruitcakes like Koresh have been demonstrating such evil corruption\\nfor centuries.\\n-- \\nThe Old Frog's Almanac - A Salute to That Old Frog Hisse'f, Ryugen Fisher \\n     (604) 245-3205 (v32) (604) 245-4366 (2400x4) SCO XENIX 2.3.2 GT \\n  Ladysmith, British Columbia, CANADA. Serving Central Vancouver Island  \\nwith public access UseNet and Internet Mail - home to the Holocaust Almanac\\n\"]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train['data'][0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'sklearn.datasets.base.Bunch'>\n"
     ]
    }
   ],
   "source": [
    "print(type(data_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 3, 2, 0])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2034x33809 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 224893 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you want a smaller set use etl.load('../ml_challenge/<filename>) \n",
    "#data_set = etl.load_dir('../ml_challenge')\n",
    "# handy when developing etl in this notebook\n",
    "from importlib import reload\n",
    "if 'etl' in globals():\n",
    "    reload(etl)\n",
    "else:\n",
    "    import etl\n",
    "data_set = etl.load_dir('../ml_challenge/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_X_train[0:4] \n",
      " ['AADtjAAywX8ADD0gAADACQAA7AsAMuwMACj9gAIQPSAAAMAJAAD/jAAAQJ0ADMAfAAhIAAAQwZ8ACMAfAAzsDA==', 'AAb/////AAAAAAADbGx4CgAgAJgLAKkRwCAAmBuQkPWgmSDAIACZCMAgAJgrwCAAmQjBAADRAAChAACBAADgCA==', 'jIkAGI1LAACNaQAAAShIJK1pAACMSQAgJSkAARAA//GsSQAgjUIAAK+iABiMwgAIAAAwIYxCAACsogAMPAIAAA==', 'WDAwAFAwEACnSAAAWDDR4lBAEABYQNHeUEAQAFhAMABQQBAAWEAwBFBAEABYQNHaWDAwCFAwEABYMEAAUDAQAA==']\n",
      "orig_Y_train[0:4] \n",
      " ['powerpc', 'xtensa', 'mips', 's390']\n",
      "orig_train_targets[0:4] \n",
      " [['alphaev56', 'arm', 'powerpc', 's390', 'sh4', 'xtensa'], ['alphaev56', 'avr', 'mipsel', 'powerpc', 'sh4', 'xtensa'], ['avr', 'm68k', 'mips', 'powerpc', 'sh4', 'sparc'], ['arm', 'avr', 'm68k', 'mips', 'mipsel', 's390']]\n"
     ]
    }
   ],
   "source": [
    "orig_X_train, orig_Y_train, orig_train_targets = data_set['train']['binary_data'], data_set['train']['answers'], data_set['train']['targets']\n",
    "orig_X_dev, orig_Y_dev, orig_dev_targets = data_set['dev']['binary_data'], data_set['dev']['answers'], data_set['dev']['targets']\n",
    "orig_X_test, orig_Y_test, orig_test_targets = data_set['test']['binary_data'], data_set['test']['answers'], data_set['test']['targets']\n",
    "\n",
    "print('orig_X_train[0:4]', '\\n', orig_X_train[0:4])\n",
    "print('orig_Y_train[0:4]', '\\n', orig_Y_train[0:4])\n",
    "print('orig_train_targets[0:4]', '\\n', orig_train_targets[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hex_X_train[0:4] [ '0000ed8c0032c17f000c3d200000c0090000ec0b0032ec0c0028fd8002103d200000c0090000ff8c0000409d000cc01f000848000010c19f0008c01f000cec0c'\n",
      " '0006ffffffff0000000000036c6c780a002000980b00a911c02000981b9090f5a09920c020009908c02000982bc020009908c10000d10000a10000810000e008'\n",
      " '8c8900188d4b00008d69000001284824ad6900008c490020252900011000fff1ac4900208d420000afa200188cc20008000030218c420000aca2000c3c020000'\n",
      " '5830300050301000a74800005830d1e2504010005840d1de50401000584030005040100058403004504010005840d1da58303008503010005830400050301000'] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "hex_X_train = etl.hex_data(orig_X_train)\n",
    "hex_X_dev = etl.hex_data(orig_X_dev)\n",
    "hex_X_test = etl.hex_data(orig_X_test)\n",
    "\n",
    "print('hex_X_train[0:4]', hex_X_train[0:4], '\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The order of classes from CountVectorizer.classes_ may be different from etl.SUPPORTED_ARCHITECTURES\n",
    "# We will over-write y_train and y_dev below with .classes_\n",
    "y_train = list(map(etl.SUPPORTED_ARCHITECTURES.index, orig_Y_train))\n",
    "y_dev = list(map(etl.SUPPORTED_ARCHITECTURES.index, orig_Y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[8, 10, 4, 2] 2048\n",
      "[5, 3, 11, 1] 256\n"
     ]
    }
   ],
   "source": [
    "print(y_train[0:4], len(y_train))\n",
    "print(y_dev[0:4], len(y_dev))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "65536"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2**16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Automatically created module for IPython interactive environment\n",
      "Usage: ipykernel_launcher.py [options]\n",
      "\n",
      "Options:\n",
      "  -h, --help            show this help message and exit\n",
      "  --report              Print a detailed classification report.\n",
      "  --chi2_select=SELECT_CHI2\n",
      "                        Select some number of features using a chi-squared\n",
      "                        test\n",
      "  --confusion_matrix    Print the confusion matrix.\n",
      "  --top10               Print ten most discriminative terms per class for\n",
      "                        every classifier.\n",
      "  --all_categories      Whether to use all categories or not.\n",
      "  --use_hashing         Use a hashing vectorizer.\n",
      "  --n_features=N_FEATURES\n",
      "                        n_features when using the hashing vectorizer.\n",
      "  --filtered            Remove newsgroup information that is easily overfit:\n",
      "                        headers, signatures, and quoting.\n",
      "\n",
      "28160 documents - 3.604MB (training set)\n",
      "3584 documents - 0.459MB (dev set)\n",
      "\n",
      "Extracting features from the training data using a sparse vectorizer\n"
     ]
    }
   ],
   "source": [
    "# Author: Peter Prettenhofer <peter.prettenhofer@gmail.com>\n",
    "#         Olivier Grisel <olivier.grisel@ensta.org>\n",
    "#         Mathieu Blondel <mathieu@mblondel.org>\n",
    "#         Lars Buitinck\n",
    "# License: BSD 3 clause\n",
    "debug = True\n",
    "\n",
    "from __future__ import print_function\n",
    "\n",
    "import logging\n",
    "import numpy as np\n",
    "from optparse import OptionParser\n",
    "import sys\n",
    "from time import time\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import Perceptron\n",
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.extmath import density\n",
    "from sklearn import metrics\n",
    "\n",
    "\n",
    "# Display progress logs on stdout\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "                    format='%(asctime)s %(levelname)s %(message)s')\n",
    "\n",
    "\n",
    "# parse commandline arguments\n",
    "op = OptionParser()\n",
    "op.add_option(\"--report\",\n",
    "              action=\"store_true\", dest=\"print_report\",\n",
    "              help=\"Print a detailed classification report.\")\n",
    "op.add_option(\"--chi2_select\",\n",
    "              action=\"store\", type=\"int\", dest=\"select_chi2\",\n",
    "              help=\"Select some number of features using a chi-squared test\")\n",
    "op.add_option(\"--confusion_matrix\",\n",
    "              action=\"store_true\", dest=\"print_cm\",\n",
    "              help=\"Print the confusion matrix.\")\n",
    "op.add_option(\"--top10\",\n",
    "              action=\"store_true\", dest=\"print_top10\",\n",
    "              help=\"Print ten most discriminative terms per class\"\n",
    "                   \" for every classifier.\")\n",
    "op.add_option(\"--all_categories\",\n",
    "              action=\"store_true\", dest=\"all_categories\", default=True,\n",
    "              help=\"Whether to use all categories or not.\")\n",
    "op.add_option(\"--use_hashing\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Use a hashing vectorizer.\")\n",
    "op.add_option(\"--n_features\",\n",
    "              action=\"store\", type=int, default=2 ** 16,\n",
    "              help=\"n_features when using the hashing vectorizer.\")\n",
    "op.add_option(\"--filtered\",\n",
    "              action=\"store_true\",\n",
    "              help=\"Remove newsgroup information that is easily overfit: \"\n",
    "                   \"headers, signatures, and quoting.\")\n",
    "\n",
    "\n",
    "def is_interactive():\n",
    "    return not hasattr(sys.modules['__main__'], '__file__')\n",
    "\n",
    "# work-around for Jupyter notebook and IPython console\n",
    "argv = [] if is_interactive() else sys.argv[1:]\n",
    "(opts, args) = op.parse_args(argv)\n",
    "if len(args) > 0:\n",
    "    op.error(\"this script takes no arguments.\")\n",
    "    sys.exit(1)\n",
    "\n",
    "print(__doc__)\n",
    "op.print_help()\n",
    "print()\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "\n",
    "\n",
    "# order of labels in `target_names` can be different from `categories`\n",
    "target_names = etl.SUPPORTED_ARCHITECTURES\n",
    "\n",
    "\n",
    "def size_mb(docs):\n",
    "    return sum(len(s) for s in docs) / 1e6\n",
    "\n",
    "data_train_size_mb = size_mb(hex_X_train)\n",
    "data_test_size_mb = size_mb(hex_X_dev)\n",
    "\n",
    "print(\"%d documents - %0.3fMB (training set)\" % (\n",
    "    len(hex_X_train), data_train_size_mb))\n",
    "print(\"%d documents - %0.3fMB (dev set)\" % (\n",
    "    len(hex_X_dev), data_test_size_mb))\n",
    "print()\n",
    "\n",
    "# rename until we make this a function\n",
    "X_train = hex_X_train\n",
    "X_test = hex_X_dev\n",
    "\n",
    "print(\"Extracting features from the training data using a sparse vectorizer\")\n",
    "t0 = time()\n",
    "if opts.use_hashing:\n",
    "    vectorizer = HashingVectorizer(stop_words='english', alternate_sign=False,\n",
    "                                   n_features=opts.n_features)\n",
    "    X_train = vectorizer.transform(X_train)\n",
    "else:\n",
    "    vec_opts = {\n",
    "        \"ngram_range\": (1, 6),  # allow n-grams of 1-4 words in length (32-bits)\n",
    "        \"analyzer\": \"word\",     # analyze hex words\n",
    "        \"token_pattern\": \"..\",  # treat two characters as a word (e.g. 4b)\n",
    "        \"min_df\": 2,          # \n",
    "        \"max_df\": 0.7,\n",
    "    }\n",
    "    #v = CountVectorizer(**vec_opts)\n",
    "    #X_train = v.fit_transform(X_train)\n",
    "\n",
    "    idf_opts = {\"use_idf\": True}\n",
    "    #vectorizer = TfidfTransformer(**idf_opts)\n",
    "    vec_opts.update(idf_opts)\n",
    "    vectorizer = TfidfVectorizer(**vec_opts)\n",
    "    X_train = vectorizer.fit_transform(X_train)\n",
    "    \n",
    "print('list(v.vocabulary_.items())[0:10]', list(v.vocabulary_.items())[0:10])    \n",
    "    \n",
    "print(\"vocabulary size: {}\".format(len(v.vocabulary_)))\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_train_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_train.shape)\n",
    "print()\n",
    "\n",
    "print(\"Extracting features from the test data using the same vectorizer\")\n",
    "t0 = time()\n",
    "#vec_opts.update({'vocabulary': v.vocabulary_})\n",
    "#v_test = CountVectorizer(**vec_opts)\n",
    "#X_test = v_test.fit_transform(X_test)\n",
    "X_test = vectorizer.transform(X_test)\n",
    "duration = time() - t0\n",
    "print(\"done in %fs at %0.3fMB/s\" % (duration, data_test_size_mb / duration))\n",
    "print(\"n_samples: %d, n_features: %d\" % X_test.shape)\n",
    "print()\n",
    "\n",
    "# mapping from integer feature name to original token string\n",
    "if opts.use_hashing:\n",
    "    feature_names = None\n",
    "else:\n",
    "    feature_names = vectorizer.get_feature_names()\n",
    "\n",
    "# split a training set and a test set\n",
    "# y_train = list(map(v.classes_.index, orig_Y_train))\n",
    "# y_test = list(map(v.classes_.index, orig_Y_dev))\n",
    "# print('y_train[0:4]', y_train[0:4], 'y_test[0:4]', y_test[0:4])\n",
    "\n",
    "if False: #opts.select_chi2:\n",
    "    print(\"Extracting %d best features by a chi-squared test\" %\n",
    "          opts.select_chi2)\n",
    "    t0 = time()\n",
    "    ch2 = SelectKBest(chi2, k=opts.select_chi2)\n",
    "    X_train = ch2.fit_transform(X_train, y_train)\n",
    "    X_test = ch2.transform(X_test)\n",
    "    if feature_names:\n",
    "        # keep selected feature names\n",
    "        feature_names = [feature_names[i] for i\n",
    "                         in ch2.get_support(indices=True)]\n",
    "    print(\"done in %fs\" % (time() - t0))\n",
    "    print()\n",
    "\n",
    "if feature_names:\n",
    "    feature_names = np.asarray(feature_names)\n",
    "\n",
    "\n",
    "def trim(s):\n",
    "    \"\"\"Trim string to fit on terminal (assuming 80-column display)\"\"\"\n",
    "    return s if len(s) <= 80 else s[:77] + \"...\"\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# #############################################################################\n",
    "# Benchmark classifiers\n",
    "def benchmark(clf, X_train, X_test, y_train, y_test):\n",
    "    \"\"\"\n",
    "    @param X_train: tfid vectorized x input training data\n",
    "    @param X_test: tfid vectorized x input test data\n",
    "    \"\"\"\n",
    "    print('_' * 80)\n",
    "    print(\"Training: \")\n",
    "    print(clf)\n",
    "    t0 = time()\n",
    "    print('X_train.shape', X_train.shape, \"y_train.shape\", len(y_train))\n",
    "    clf.fit(X_train, y_train)\n",
    "    train_time = time() - t0\n",
    "    print(\"train time: %0.3fs\" % train_time)\n",
    "\n",
    "    t0 = time()\n",
    "    pred = clf.predict(X_test)\n",
    "    test_time = time() - t0\n",
    "    print(\"test time:  %0.3fs\" % test_time)\n",
    "    \n",
    "    if debug:\n",
    "        print(\"Some samples\")\n",
    "        print(\"y_test[0:3]\", y_test[0:3], \"pred[0:3]\", pred[0:3])\n",
    "    score = metrics.accuracy_score(y_test, pred)\n",
    "    print(\"accuracy:   %0.3f\" % score)\n",
    "\n",
    "    if hasattr(clf, 'coef_'):\n",
    "        print(\"dimensionality: %d\" % clf.coef_.shape[1])\n",
    "        print(\"density: %f\" % density(clf.coef_))\n",
    "\n",
    "        if opts.print_top10 and feature_names is not None:\n",
    "            print(\"top 10 keywords per class:\")\n",
    "            for i, label in enumerate(target_names):\n",
    "                top10 = np.argsort(clf.coef_[i])[-10:]\n",
    "                print(trim(\"%s: %s\" % (label, \" \".join(feature_names[top10]))))\n",
    "        print()\n",
    "\n",
    "    if opts.print_report:\n",
    "        print(\"classification report:\")\n",
    "        print(metrics.classification_report(y_test, pred,\n",
    "                                            target_names=target_names))\n",
    "\n",
    "    if opts.print_cm:\n",
    "        print(\"confusion matrix:\")\n",
    "        print(metrics.confusion_matrix(y_test, pred))\n",
    "\n",
    "    print()\n",
    "    clf_descr = str(clf).split('(')[0]\n",
    "    return clf_descr, score, train_time, test_time\n",
    "\n",
    "\n",
    "results = []\n",
    "for clf, name in (\n",
    "        (RidgeClassifier(tol=1e-2, solver=\"lsqr\"), \"Ridge Classifier\"),\n",
    "        (Perceptron(n_iter=50), \"Perceptron\"),\n",
    "        (PassiveAggressiveClassifier(n_iter=50), \"Passive-Aggressive\"),\n",
    "        (KNeighborsClassifier(n_neighbors=10), \"kNN\"),\n",
    "        (RandomForestClassifier(n_estimators=100), \"Random forest\")):\n",
    "    print('=' * 80)\n",
    "    print(name)\n",
    "    results.append(benchmark(clf, X_train, X_test, orig_Y_train, orig_Y_dev))\n",
    "\n",
    "for penalty in [\"l2\", \"l1\"]:\n",
    "    print('=' * 80)\n",
    "    print(\"%s penalty\" % penalty.upper())\n",
    "    # Train Liblinear model\n",
    "    results.append(benchmark(LinearSVC(penalty=penalty, dual=False,\n",
    "                                       tol=1e-3), X_train, X_test, orig_Y_train, orig_Y_dev))\n",
    "\n",
    "    # Train SGD model\n",
    "    results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                           penalty=penalty), X_train, X_test, orig_Y_train, orig_Y_dev))\n",
    "\n",
    "# Train SGD with Elastic Net penalty\n",
    "print('=' * 80)\n",
    "print(\"Elastic-Net penalty\")\n",
    "results.append(benchmark(SGDClassifier(alpha=.0001, n_iter=50,\n",
    "                                       penalty=\"elasticnet\"), X_train, X_test, orig_Y_train, orig_Y_dev))\n",
    "\n",
    "# Train NearestCentroid without threshold\n",
    "print('=' * 80)\n",
    "print(\"NearestCentroid (aka Rocchio classifier)\")\n",
    "results.append(benchmark(NearestCentroid(), X_train, X_test, orig_Y_train, orig_Y_dev))\n",
    "\n",
    "# Train sparse Naive Bayes classifiers\n",
    "print('=' * 80)\n",
    "print(\"Naive Bayes\")\n",
    "results.append(benchmark(MultinomialNB(alpha=.01), X_train, X_test, orig_Y_train, orig_Y_dev))\n",
    "results.append(benchmark(BernoulliNB(alpha=.01), X_train, X_test, orig_Y_train, orig_Y_dev))\n",
    "\n",
    "print('=' * 80)\n",
    "print(\"LinearSVC with L1-based feature selection\")\n",
    "# The smaller C, the stronger the regularization.\n",
    "# The more regularization, the more sparsity.\n",
    "results.append(benchmark(Pipeline([\n",
    "  ('feature_selection', SelectFromModel(LinearSVC(penalty=\"l1\", dual=False,\n",
    "                                                  tol=1e-3))),\n",
    "  ('classification', LinearSVC(penalty=\"l2\"))]), X_train, X_test, orig_Y_train, orig_Y_dev))\n",
    "\n",
    "# make some plots\n",
    "\n",
    "indices = np.arange(len(results))\n",
    "\n",
    "results = [[x[i] for x in results] for i in range(4)]\n",
    "\n",
    "clf_names, score, training_time, test_time = results\n",
    "training_time = np.array(training_time) / np.max(training_time)\n",
    "test_time = np.array(test_time) / np.max(test_time)\n",
    "\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.title(\"Score\")\n",
    "plt.barh(indices, score, .2, label=\"score\", color='navy')\n",
    "plt.barh(indices + .3, training_time, .2, label=\"training time\",\n",
    "         color='c')\n",
    "plt.barh(indices + .6, test_time, .2, label=\"test time\", color='darkorange')\n",
    "plt.yticks(())\n",
    "plt.legend(loc='best')\n",
    "plt.subplots_adjust(left=.25)\n",
    "plt.subplots_adjust(top=.95)\n",
    "plt.subplots_adjust(bottom=.05)\n",
    "\n",
    "for i, c in zip(indices, clf_names):\n",
    "    plt.text(-.3, i, c)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "dfr = pd.DataFrame(results).transpose()\n",
    "dfr.columns=['classifier', 'accuracy', 'train_time', 'test_time']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>RidgeClassifier</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>1.01744</td>\n",
       "      <td>0.00252819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Perceptron</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>0.547086</td>\n",
       "      <td>0.00270653</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PassiveAggressiveClassifier</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>1.56262</td>\n",
       "      <td>0.00758171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>KNeighborsClassifier</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>0.00676441</td>\n",
       "      <td>0.202344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>0.980469</td>\n",
       "      <td>2.62882</td>\n",
       "      <td>0.0496018</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.689969</td>\n",
       "      <td>0.00208521</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.598987</td>\n",
       "      <td>0.00243831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LinearSVC</td>\n",
       "      <td>0.984375</td>\n",
       "      <td>1.00739</td>\n",
       "      <td>0.00111461</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>1.5408</td>\n",
       "      <td>0.00335622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>1.85088</td>\n",
       "      <td>0.00254416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NearestCentroid</td>\n",
       "      <td>0.949219</td>\n",
       "      <td>0.0341663</td>\n",
       "      <td>0.00348496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>MultinomialNB</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>0.0297809</td>\n",
       "      <td>0.00177693</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BernoulliNB</td>\n",
       "      <td>0.992188</td>\n",
       "      <td>0.0301452</td>\n",
       "      <td>0.060282</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Pipeline</td>\n",
       "      <td>0.988281</td>\n",
       "      <td>1.00833</td>\n",
       "      <td>0.00412846</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     classifier  accuracy  train_time   test_time\n",
       "0               RidgeClassifier  0.996094     1.01744  0.00252819\n",
       "1                    Perceptron  0.988281    0.547086  0.00270653\n",
       "2   PassiveAggressiveClassifier  0.992188     1.56262  0.00758171\n",
       "3          KNeighborsClassifier  0.984375  0.00676441    0.202344\n",
       "4        RandomForestClassifier  0.980469     2.62882   0.0496018\n",
       "5                     LinearSVC  0.996094    0.689969  0.00208521\n",
       "6                 SGDClassifier  0.996094    0.598987  0.00243831\n",
       "7                     LinearSVC  0.984375     1.00739  0.00111461\n",
       "8                 SGDClassifier  0.988281      1.5408  0.00335622\n",
       "9                 SGDClassifier  0.992188     1.85088  0.00254416\n",
       "10              NearestCentroid  0.949219   0.0341663  0.00348496\n",
       "11                MultinomialNB  0.996094   0.0297809  0.00177693\n",
       "12                  BernoulliNB  0.992188   0.0301452    0.060282\n",
       "13                     Pipeline  0.988281     1.00833  0.00412846"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>train_time</th>\n",
       "      <th>test_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>14</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>14.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>0.996094</td>\n",
       "      <td>1.562622</td>\n",
       "      <td>0.004128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>3</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           classifier   accuracy  train_time  test_time\n",
       "count              14  14.000000   14.000000  14.000000\n",
       "unique             11   6.000000   14.000000  14.000000\n",
       "top     SGDClassifier   0.996094    1.562622   0.004128\n",
       "freq                3   4.000000    1.000000   1.000000"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfr.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
