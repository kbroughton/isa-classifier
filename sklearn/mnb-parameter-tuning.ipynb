{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# mnb parameter tuning (Multinomial Naieve Bayes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "import etl\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "!free -h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../ml_challenge/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_set = etl.load_dir('../ml_challenge')\n",
    "data_set = etl.load('../ml_challenge/4096_512_512_6f9ef7d8.json')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "orig_X_train, orig_Y_train, orig_train_targets = data_set['train']['binary_data'], data_set['train']['answers'], data_set['train']['targets']\n",
    "orig_X_dev, orig_Y_dev, orig_dev_targets = data_set['dev']['binary_data'], data_set['dev']['answers'], data_set['dev']['targets']\n",
    "orig_X_test, orig_Y_test, orig_test_targets = data_set['test']['binary_data'], data_set['test']['answers'], data_set['test']['targets']\n",
    "\n",
    "print('orig_X_train[0:4]', '\\n', orig_X_train[0:4])\n",
    "print('orig_Y_train[0:4]', '\\n', orig_Y_train[0:4])\n",
    "print('orig_train_targets[0:4]', '\\n', orig_train_targets[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_X_train = etl.hex_data(orig_X_train)\n",
    "hex_X_dev = etl.hex_data(orig_X_dev)\n",
    "hex_X_test = etl.hex_data(orig_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_from_target(probs, allowed_Y, supported_architectures):\n",
    "    \"\"\"\n",
    "    Improve our chances by taking the max over the possible targets (6 instead of 12)\n",
    "    @probs: numerical array of shape (m, n_classes)\n",
    "    @allowed_Y: ones-hot array of shape (m, n_classes)\n",
    "    @supported_architectures: Use CountVectorizer.classes_ not etl.SUPPORTED_ARCHITECTURES for ordering\n",
    "    \n",
    "    @returns: (m, 1) of the most likely ISA arch names after discards or\n",
    "             (m, n_classes) one-hot representation of best guess\n",
    "    \"\"\"\n",
    "    return list(map(supported_architectures.__getitem__, np.argmax(probs*allowed_Y, axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_results(predictions, probs, orig_Y, param_str, error_type='train'):\n",
    "    \"\"\"\n",
    "    @returns tuple(index, prediction, actual_value)\n",
    "    \"\"\"\n",
    "    wrong = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != orig_Y[i]:\n",
    "            wrong.append([i, predictions[i], orig_Y[i], probs[i]])\n",
    "    if error_type == 'train':\n",
    "        print(param_str)\n",
    "    print('{} error: {}'.format(error_type, len(wrong)/len(predictions)))\n",
    "    return wrong, len(wrong)/len(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['alpha'] = [0.0001, 0.001, 0.1]\n",
    "params['max_ngram_range'] = [4, 6, 8]\n",
    "params['smooth_idf'] = [True, False]\n",
    "params['norm'] = ['l2', None]\n",
    "params['sublinear_tf'] = [True, False]\n",
    "params['min_df'] = [1, 2]\n",
    "params['max_df'] = [.5, .9]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def search_hyperparams(params):\n",
    "    df = pd.DataFrame()\n",
    "    wrong_train = {}\n",
    "    wrong_dev = {}\n",
    "    for alpha in params['alpha']:\n",
    "        for max_ngram_range in params['max_ngram_range']:\n",
    "            for smooth_idf in params['smooth_idf']:\n",
    "                for norm in params['norm']:\n",
    "                    for sublinear_tf in params['sublinear_tf']:\n",
    "                        for min_df in params['min_df']:\n",
    "                            for max_df in params['max_df']:\n",
    "                                vec_opts = {\n",
    "                                    \"ngram_range\": (1, max_ngram_range),  # allow n-grams of 1-4 words in length (32-bits)\n",
    "                                    \"analyzer\": \"word\",     # analyze hex words\n",
    "                                    \"token_pattern\": \"..\",  # treat two characters as a word (e.g. 4b)\n",
    "                                    \"min_df\": min_df,          # for demo purposes, be very selective about features\n",
    "                                    \"max_df\": max_df\n",
    "                                }\n",
    "                                v = CountVectorizer(**vec_opts)\n",
    "                                X_cv = v.fit_transform(hex_X_train)\n",
    "\n",
    "                                idf_opts = {\"use_idf\": True}\n",
    "                                idf = TfidfTransformer(**idf_opts)\n",
    "\n",
    "                                # perform the idf transform\n",
    "                                X_idf = idf.fit_transform(X_cv)\n",
    "\n",
    "                                mnbClassifier = MultinomialNB(alpha=alpha)\n",
    "\n",
    "                                mnb_model = mnbClassifier.fit(X_idf, np.array(orig_Y_train))\n",
    "\n",
    "                                Y_train, allowed_Y_train = etl.class_to_ones_hot(orig_Y_train, orig_train_targets, mnb_model.classes_.tolist())\n",
    "                                Y_dev, allowed_Y_dev = etl.class_to_ones_hot(orig_Y_dev, orig_dev_targets, mnb_model.classes_.tolist())\n",
    "                                Y_test, allowed_Y_test = etl.class_to_ones_hot(orig_Y_test, orig_test_targets, mnb_model.classes_.tolist())\n",
    "\n",
    "                                probs_train = mnb_model.predict_proba(X_idf)\n",
    "\n",
    "                                predictions = guess_from_target(probs_train, allowed_Y_train, mnb_model.classes_.tolist())\n",
    "\n",
    "                                param_str = \"alpha={}, max_ngram_range={}, smooth_idf={}, norm={}, sublinear_tf={}, min_df={}, max_df={}\".format(\n",
    "                                alpha, max_ngram_range, smooth_idf, norm, sublinear_tf, min_df, max_df)\n",
    "                                mismatches, train_error = describe_results(predictions, probs_train, orig_Y_train, param_str)\n",
    "                                \n",
    "                                wrong_train[param_str + '-train-' + str(train_error)] = mismatches\n",
    "                                \n",
    "                                vec_opts.update({'vocabulary': v.vocabulary_})\n",
    "                                v_dev = CountVectorizer(**vec_opts)\n",
    "                                X_cv_dev = v_dev.transform(hex_X_dev)\n",
    "                                X_idf_dev = idf.transform(X_cv_dev)\n",
    "                                probs_dev = mnb_model.predict_proba(X_idf_dev)\n",
    "\n",
    "                                predictions_dev = guess_from_target(probs_dev, allowed_Y_dev, mnb_model.classes_.tolist())\n",
    "                                mismatches, dev_error = describe_results(predictions_dev, probs_dev, orig_Y_dev, param_str, error_type='dev')\n",
    "                                wrong_dev[param_str + '-dev-' + str(dev_error)] = mismatches\n",
    "                                \n",
    "                                params_dict = {'alpha': alpha, 'max_ngram_range': max_ngram_range, \n",
    "                                                'smooth_idf': smooth_idf, 'norm': norm, \n",
    "                                          'sublinear_tf': sublinear_tf, 'min_df': min_df, \n",
    "                                          'max_df': max_df, 'train_error': train_error, \n",
    "                                          'dev_error': dev_error}\n",
    "                                df = df.append(params_dict, ignore_index=True)\n",
    "\n",
    "    return wrong_train, wrong_dev, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "def param_space_size(params):\n",
    "    prod = 1\n",
    "    for k,v in params.items():\n",
    "        prod *= len(v)\n",
    "    return prod\n",
    "param_space_size(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_train, wrong_dev, df_mnb = search_hyperparams(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnb.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mnb.groupby(by='train_error').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_mnb.groupby(by='dev_error').describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_min = df_mnb['train_error'].min()\n",
    "dev_min = df_mnb['dev_error'].min()\n",
    "print(\"train_min\", train_min, train_min*500)\n",
    "print(\"dev_min\", dev_min, dev_min*500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_mnb.loc[df_mnb['dev_error'] == dev_min]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This shows that the hyperparams mnb is sensitive to for min dev_error are\n",
    "alpha (<= 0.0001), ngram_range (=6), min_df (=2.0)\n",
    "max_df, norm, smoothin_idf, sublinear_tf are not selecting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's run the grid search again honing in on alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {}\n",
    "params['alpha'] = [1e-6, 1e-5, 1e-4]\n",
    "params['max_ngram_range'] = [6,]\n",
    "params['smooth_idf'] = [True]\n",
    "params['norm'] = ['l2']\n",
    "params['sublinear_tf'] = [True]\n",
    "params['min_df'] = [2]\n",
    "params['max_df'] = [.7]\n",
    "\n",
    "param_space_size(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_set = etl.load_dir('../ml_challenge/')\n",
    "orig_X_train, orig_Y_train, orig_train_targets = data_set['train']['binary_data'], data_set['train']['answers'], data_set['train']['targets']\n",
    "orig_X_dev, orig_Y_dev, orig_dev_targets = data_set['dev']['binary_data'], data_set['dev']['answers'], data_set['dev']['targets']\n",
    "orig_X_test, orig_Y_test, orig_test_targets = data_set['test']['binary_data'], data_set['test']['answers'], data_set['test']['targets']\n",
    "\n",
    "print('orig_X_train[0:4]', '\\n', orig_X_train[0:4])\n",
    "print('orig_Y_train[0:4]', '\\n', orig_Y_train[0:4])\n",
    "print('orig_train_targets[0:4]', '\\n', orig_train_targets[0:4])\n",
    "\n",
    "hex_X_train = etl.hex_data(orig_X_train)\n",
    "hex_X_dev = etl.hex_data(orig_X_dev)\n",
    "hex_X_test = etl.hex_data(orig_X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_train, wrong_dev, df_mnb = search_hyperparams(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k,v in wrong_dev.items():\n",
    "    print(k)\n",
    "    print(len(wrong_dev[k]))\n",
    "\n",
    "for k,v in wrong_train.items():\n",
    "    print(k)\n",
    "    print(len(wrong_train[k]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = pd.DataFrame(list(wrong_dev.values())[0])\n",
    "wd.columns = ['index', 'wrong_prediction', 'correct', 'probs']\n",
    "wd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = lambda x: x > 1e-4\n",
    "for col in wd['probs']:\n",
    "    print(list(filter(f, col)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's interesting that the model has such high confidence for item 5 (index 2681) and yet is wrong."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}