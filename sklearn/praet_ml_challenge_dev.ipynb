{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Praetorian ML Challenge - explore data\n",
    "\n",
    "Notes:\n",
    "On https://p16.praetorian.com/blog/machine-learning-tutorial the link \"Machine Learning Binaries\" is broken"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Discussion\n",
    "At first glance, this may seem like an unsupervised task, but since we can guess wrong and get the correct answer for a given challenge, we can build a supervised training set\n",
    "\n",
    "Inspecting a few ISA's for the supported architectures, it appears there are typically hundreds of instructions, not tens of thousands, so a non-sparse matrix approach might work fine for a first principles text embedding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/projects/isa-classifier\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in /usr/local/lib/python2.7/dist-packages (from -r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: urllib3<1.23,>=1.21.1 in /usr/local/lib/python2.7/dist-packages (from requests->-r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: idna<2.7,>=2.5 in /usr/local/lib/python2.7/dist-packages (from requests->-r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python2.7/dist-packages (from requests->-r ../requirements.txt (line 1))\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python2.7/dist-packages (from requests->-r ../requirements.txt (line 1))\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#%%writefile etl.py\n",
    "\n",
    "from __future__ import print_function\n",
    "import base64\n",
    "import binascii\n",
    "import datetime\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import random\n",
    "import requests\n",
    "import time\n",
    "import uuid\n",
    "\n",
    "SUPPORTED_ARCHITECTURES = [\"avr\", \"alphaev56\", \"arm\", \"m68k\", \"mips\", \n",
    "                           \"mipsel\", \"powerpc\", \"s390\", \"sh4\", \"sparc\", \"x86_64\", \"xtensa\"]\n",
    "\n",
    "logging.basicConfig(level=logging.INFO,\n",
    "    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "\n",
    "class Server(object):\n",
    "    url = 'https://mlb.praetorian.com'\n",
    "    log = logging.getLogger(__name__)\n",
    "\n",
    "    def __init__(self):\n",
    "        self.session = requests.session()\n",
    "        # in a sample of a few dozen, self.binary is either 32 or 36 bytes so pad X to 36 byte columns\n",
    "        self.binary  = None\n",
    "        self.hash    = None\n",
    "        self.wins    = 0\n",
    "        self.targets = []\n",
    "        self.rate_limit_count = 0\n",
    "        self.unknown_server_exception_count = 0\n",
    "        self.retry_wait = 10\n",
    "        self.count = 0\n",
    "        self.failure_record = []\n",
    "        self.start_time = datetime.datetime.now()\n",
    "        self.response = None\n",
    "\n",
    "    def _request(self, route, method='get', data=None):\n",
    "        while True:\n",
    "            if self.count > 597:\n",
    "                print('Resetting session at count {}'.format(self.count))\n",
    "                self.session = requests.session()\n",
    "            try:\n",
    "                if method == 'get':\n",
    "                    r = self.session.get(self.url + route)\n",
    "                else:\n",
    "                    r = self.session.post(self.url + route, data=data)\n",
    "                self.status_code = r.status_code\n",
    "                if r.status_code == 429:\n",
    "                    self.rate_limit_count += 1\n",
    "                    self.failure_record.append({'type': 'rate_limit',\n",
    "                                                'count': self.count,\n",
    "                                                'time': (datetime.datetime.now() -\n",
    "                                                         self.start_time).total_seconds()})\n",
    "                    raise Exception('Rate Limit Exception')\n",
    "                if r.status_code == 500:\n",
    "                    self.unknown_server_exception_count += 1\n",
    "                    self.failure_record.append({'type': 'unknown_server_exception',\n",
    "                                                'count': self.count,\n",
    "                                                'time': (datetime.datetime.now() -\n",
    "                                                         self.start_time).total_seconds()})\n",
    "                    raise Exception('Unknown Server Exception')\n",
    "                self.response = r\n",
    "                return r.json()\n",
    "            except Exception as e:\n",
    "                self.log.error(e)\n",
    "                self.log.info('Waiting 60 seconds before next request')\n",
    "                time.sleep(60)\n",
    "                self.status_code = None\n",
    "\n",
    "    def get(self):\n",
    "        r = self._request(\"/challenge\")\n",
    "        self.targets = r.get('target', [])\n",
    "        # removed base64.base64decode(r.get('binary', '')) to allow writes to disk without re-encoding\n",
    "        self.binary  = r.get('binary', '')\n",
    "        return r\n",
    "\n",
    "    def post(self, target):\n",
    "        r = self._request(\"/solve\", method=\"post\", data={\"target\": target})\n",
    "        self.wins = r.get('correct', 0)\n",
    "        self.hash = r.get('hash', self.hash)\n",
    "        self.ans  = r.get('target', 'unknown')\n",
    "        return r\n",
    "    \n",
    "    def get_data(self, number=10000):\n",
    "        \"\"\"\n",
    "        Retrieves data in format\n",
    "        @param number: nubmer of samples to return\n",
    "        @returns {binary_data: values, targets: values, answers: values}\n",
    "        where binary_data = [ \"<base64 encoded string>\", ... ]\n",
    "        targets =  [ \"avr\", \"x86_64\", ... ]\n",
    "        answers = [one item from targets,]\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        # If we grab a large data set make it a little more efficient by pre-allocating\n",
    "        data['binary_data'] = [None]*number\n",
    "        data['targets'] = [None]*number\n",
    "        data['answers'] = [None]*number\n",
    "        for i in range(number):\n",
    "            count = 0\n",
    "            self.get()\n",
    "            while((self.status_code != 200) and (count < MAX_RETRIES) ):\n",
    "                print('Status code != 200. Retrying')\n",
    "                count = count + 1\n",
    "                self.get()\n",
    "            data['binary_data'][i] = self.binary\n",
    "            data['targets'][i] = self.targets\n",
    "            self.post(self.targets[0])\n",
    "            while((self.status_code != 200) and (count < MAX_RETRIES) ):\n",
    "                print('post status code {}'.format(self.status_code))\n",
    "                count = count + 1\n",
    "                self.post(self.targets[0])\n",
    "            data['answers'][i] = self.ans\n",
    "        return data\n",
    "    \n",
    "    def get_data_sets(self, num_train=1024, num_test=128, num_dev=128):\n",
    "        \"\"\"\n",
    "        @returns {'train': {'binary_data': [num_train values],\n",
    "                            'targets': [num_train [6 values]],\n",
    "                            'answers': [num_train values],\n",
    "                  'dev': format as with 'train',\n",
    "                  'test': format as with 'train'\n",
    "        }\n",
    "        @param name_prefix: Write data to a file of this name. If None, do not write\n",
    "        \"\"\"\n",
    "        data = {}\n",
    "        data['train'] = self.get_data(num_train)\n",
    "        data['dev'] = self.get_data(num_dev)\n",
    "        data['test'] = self.get_data(num_test)\n",
    "        return data\n",
    "        \n",
    "        \n",
    "def submit(number):\n",
    "    s = Server()\n",
    "\n",
    "    for _ in range(number):\n",
    "        # query the /challenge endpoint\n",
    "        s.get()\n",
    "\n",
    "        # choose a random target and /solve\n",
    "        target = random.choice(s.targets)\n",
    "        s.post(target)\n",
    "\n",
    "        s.log.info(\"Guess:[{: >9}]   Answer:[{: >9}]   Wins:[{: >3}]\".format(target, s.ans, s.wins))\n",
    "\n",
    "        # 500 consecutive correct answers are required to win\n",
    "        # very very unlikely with current code\n",
    "        if s.hash:\n",
    "            s.log.info(\"You win! {}\".format(s.hash))    \n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        \n",
    "def store(data, root_dir=None):\n",
    "    \"\"\"\n",
    "    Store data to root_dir in a generated filename\n",
    "    \"\"\"\n",
    "    # extract some info from data to generate friendly part of filename\n",
    "    num_train = str(len(data['train']['answers']))\n",
    "    num_dev = str(len(data['dev']['answers']))\n",
    "    num_test = str(len(data['test']['answers']))\n",
    "    \n",
    "    if not root_dir:\n",
    "        root_dir = os.getcwd()\n",
    "    else:\n",
    "        root_dir = os.path.realpath(root_dir)\n",
    "    file_name = \"_\".join([num_train, num_dev, num_test, str(uuid.uuid1())[0:8]]) + \".json\"\n",
    "    file_path = os.path.join(root_dir, file_name)\n",
    "    \n",
    "    with open(file_path, 'w+') as f:\n",
    "        json.dump(data, f)\n",
    "            \n",
    "def load(path):\n",
    "    \"\"\"\n",
    "    load data from a single file.  Data must have format specified in get_data_sets        \n",
    "    \"\"\"\n",
    "    path = os.path.realpath(path)\n",
    "    with open(path, 'r') as f:\n",
    "        data = json.load(f)\n",
    "    return data\n",
    "\n",
    "def load_dir(path):\n",
    "    \"\"\"\n",
    "    load data from an entire directory.  Data must have format specified in get_data_sets\n",
    "    \"\"\"\n",
    "    merged = {'train': { 'answers': [],\n",
    "                         'targets': [],\n",
    "                         'binary_data': [] },\n",
    "              'dev': { 'answers': [],\n",
    "                         'targets': [],\n",
    "                         'binary_data': [] },\n",
    "              'test': { 'answers': [],\n",
    "                         'targets': [],\n",
    "                         'binary_data': [] }\n",
    "             }\n",
    "    if os.path.isdir(path):\n",
    "        for root, dirs, filenames in os.walk(path, topdown=True):\n",
    "            for filename in filenames:\n",
    "                if filename.endswith('.json'):\n",
    "                    merged = merge_data(merged, load(os.path.join(root, filename)))\n",
    "    else:\n",
    "        merged = load(os.path.abspath(path)\n",
    ")\n",
    "    return merged\n",
    "\n",
    "def merge_data(dict1, dict2):\n",
    "    \"\"\"\n",
    "    Perform list additions for two identically formatted dicts with lists at depth 2\n",
    "    \"\"\"\n",
    "    #_dict1 = deepcopy(dict1)\n",
    "    for key in dict2:\n",
    "        assert(key in dict1)\n",
    "        for key2 in dict2[key]:\n",
    "            assert(key2 in dict2[key])\n",
    "            dict1[key][key2] = dict1[key][key2] + dict2[key][key2]\n",
    "    return dict1\n",
    "\n",
    "def hex_data(base64_binary_data, stride=1, expected_len=None):\n",
    "    \"\"\"\n",
    "    Take an list of base64 encoded data and convert to lists of hex characters\n",
    "    @params base64_binary_data: a base64 encoded string of (presumeably) 32 or 36 hex numbers\n",
    "                                shape = (m, 1)\n",
    "    @params stride: number of bytes to consider a word\n",
    "    @params expected_len: max length of hex array, used if we need to pad shorter arrays\n",
    "    @returns: np.array([map(hexlify,base64string),])\n",
    "              shape = (m, len(base64.b64decode(base64_binary_data))/stride)\n",
    "    \"\"\"\n",
    "    # Should check that we aren't discarding https://docs.python.org/2/library/base64.html\n",
    "    # Characters that are neither in the normal base-64 alphabet nor the\n",
    "    # alternative alphabet are discarded prior to the padding check.\n",
    "    misfits = []\n",
    "    hex_X = []\n",
    "\n",
    "    for data in base64_binary_data:\n",
    "        byte_strings = []\n",
    "        data = base64.b64decode(data)\n",
    "        for i in range(0, len(data) , stride):\n",
    "            byte_strings.append(data[i:i+stride])\n",
    "        # probably not needed for most text_embeddings, but since most seem 32 or 36 it might help\n",
    "        if expected_len:\n",
    "            delta = len(byte_strings) - expected_len\n",
    "            div = delta/stride\n",
    "            remainder = delta % stride\n",
    "            if remainder or (delta < 0):\n",
    "                misfits.append(byte_strings)\n",
    "            else:\n",
    "                byte_strings.extend(['\\x00'*stride]*div)\n",
    "        hex_X.append([ binascii.hexlify(e) for e in byte_strings ])\n",
    "\n",
    "    return np.array(hex_X), misfits\n",
    "\n",
    "def class_to_ones_hot(answers, targets, supported_architectures):\n",
    "    Y = []\n",
    "    allowed_Y = []\n",
    "    for answer, target in zip(answers, targets):\n",
    "        y = [0]*len(supported_architectures)\n",
    "        index = supported_architectures.index(answer)\n",
    "        y[index] = 1\n",
    "        Y.append(y)\n",
    "        target_hot = [0]*len(supported_architectures)\n",
    "        for j, arch in enumerate(target):\n",
    "            index = supported_architectures.index(arch)\n",
    "            target_hot[index] = 1\n",
    "        allowed_Y.append(target_hot)\n",
    "    return np.array(Y), np.array(allowed_Y) \n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fetch data on first run of this notebook\n",
    "Fetch some data in the format supplied by etl.py (train, dev, test sets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Only run this cell the first time\n",
    "%cd ../\n",
    "!wget https://s3.us-east-2.amazonaws.com/isa-classifier/isa_classifier_data.tar.gz\n",
    "!tar xvf isa_classifier_data.tar.gz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls ../ml_challenge"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get and store new data\n",
    "We will store the data in as close to the original form as possible.\n",
    "We will do a small sample walkthrough of loading data and transforming it here as far as \n",
    "binary_data = [ [ 32 or 36 hex numbers ], ...].\n",
    "We also transform the ISA class into one-hot vectors.\n",
    "The word embedding transformations will be done in text_embeddings/I-TFID.ipynb, word2vec.ipynb "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = Server()\n",
    "data_set1 = s.get_data_sets(num_train=2048, num_test=256, num_dev=256)\n",
    "store(data_set1, '../ml_challenge/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_data [u'AAAAIk8Q0AtACQAP0RFiLWIP0SIhBuIiIRSSIiEN0iJiIiEI4iIhC9IiYiIhC9IiYiIhCtQA5QrQC0AA5gDgJg==', u'D5/CD7bSjQwSAdEBySHPifoxwiEVAAAAAEiLFQAAAADHBgAAAABIixKLEoXSD4VqAQAAxwUAAAAADQAAAI0UAA==', u'AAAAPAIAAIxDABQ8AgAArEMAABAAAAgAABAhPAMAACRjAAAAgxghhGQAADwDAACsZAAAJEIAAShDAAMUYP/3AA==', u'II3l/v//6/8QAOIEAJ3l/v//6xAgneVhHILjlBCB4wEAEOEHAKABAAAACgEAoOMIMJ3lAhCg4QAAg+H/AADi/g==']\n"
     ]
    }
   ],
   "source": [
    "print('binary_data', data_set1['train']['binary_data'][0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/notebooks/projects/isa-classifier/sklearn\r\n"
     ]
    }
   ],
   "source": [
    "!pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1024_128_128_eba414fa.json  2048_256_256_cb0707f0.json\r\n",
      "2048_256_256_0b966df8.json  2048_256_256_dd02089e.json\r\n",
      "2048_256_256_0baba5f4.json  2048_256_256_dd67c64e.json\r\n",
      "2048_256_256_2847388a.json  4096_512_512_6f9ef7d8.json\r\n",
      "2048_256_256_666e0b7e.json  512_128_128_76fe753c.json\r\n",
      "2048_256_256_8f6606b2.json  isa_classifier_data.tar.gz\r\n"
     ]
    }
   ],
   "source": [
    "!ls ../ml_challenge/\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "s2 = Server()\n",
    "data_set = load_dir('../ml_challenge/2048_256_256_dd67c64e.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2048"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_set['train']['binary_data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "orig_X_train[0:4] \n",
      " [u'AADtjAAywX8ADD0gAADACQAA7AsAMuwMACj9gAIQPSAAAMAJAAD/jAAAQJ0ADMAfAAhIAAAQwZ8ACMAfAAzsDA==', u'AAb/////AAAAAAADbGx4CgAgAJgLAKkRwCAAmBuQkPWgmSDAIACZCMAgAJgrwCAAmQjBAADRAAChAACBAADgCA==', u'jIkAGI1LAACNaQAAAShIJK1pAACMSQAgJSkAARAA//GsSQAgjUIAAK+iABiMwgAIAAAwIYxCAACsogAMPAIAAA==', u'WDAwAFAwEACnSAAAWDDR4lBAEABYQNHeUEAQAFhAMABQQBAAWEAwBFBAEABYQNHaWDAwCFAwEABYMEAAUDAQAA==']\n",
      "orig_Y_train[0:4] \n",
      " [u'powerpc', u'xtensa', u'mips', u's390']\n",
      "orig_train_targets[0:4] \n",
      " [[u'alphaev56', u'arm', u'powerpc', u's390', u'sh4', u'xtensa'], [u'alphaev56', u'avr', u'mipsel', u'powerpc', u'sh4', u'xtensa'], [u'avr', u'm68k', u'mips', u'powerpc', u'sh4', u'sparc'], [u'arm', u'avr', u'm68k', u'mips', u'mipsel', u's390']]\n"
     ]
    }
   ],
   "source": [
    "orig_X_train, orig_Y_train, orig_train_targets = data_set['train']['binary_data'], data_set['train']['answers'], data_set['train']['targets']\n",
    "orig_X_dev, orig_Y_dev, orig_dev_targets = data_set['dev']['binary_data'], data_set['dev']['answers'], data_set['dev']['targets']\n",
    "orig_X_test, orig_Y_test, orig_test_targets = data_set['test']['binary_data'], data_set['test']['answers'], data_set['test']['targets']\n",
    "\n",
    "print('orig_X_train[0:4]', '\\n', orig_X_train[0:4])\n",
    "print('orig_Y_train[0:4]', '\\n', orig_Y_train[0:4])\n",
    "print('orig_train_targets[0:4]', '\\n', orig_train_targets[0:4])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#reload(etl)\n",
    "import etl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11000\n",
      "0x2af8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'3030303131303030'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import binascii\n",
    "a = b'00011000'\n",
    "print(int(a))\n",
    "b = hex(int(a))\n",
    "print(b)\n",
    "binascii.hexlify(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "base64_encoded = u'GAAAABgAAAAAAAAAqAAAAABIDhBHmgJa2g4AAAAAQaAAAD0kAABetxEE/0cCAOJDAAAQIgAAQbAAAF0kAABCoA=='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\x00H\\xe7>\\x00B\\xb9\\x00\\x00\\x00\\x00&9\\x00\\x00\\x00\\x00\\x18\\x03 9\\x00\\x00\\x00\\x00 9\\x00\\x00\\x00\\x00t\\x0cr\\x01S\\x02g0 9\\x00\\x00\\x00\\x00p\\x01B\\x86LF\\x08\\x00\\n@\\x00\\x01\\x02\\x00\\x00\\x01\\x80\\x04F'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "base64.b64decode(orig_X_train[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['00', '48', 'e7', '3e', '00', '42', 'b9', '00', '00', '00', '00', '26', '39', '00', '00', '00', '00', '18', '03', '20', '39', '00', '00', '00', '00', '20', '39', '00', '00', '00', '00', '74', '0c', '72', '01', '53', '02', '67', '30', '20', '39', '00', '00', '00', '00', '70', '01', '42', '86', '4c', '46', '08', '00', '0a', '40', '00', '01', '02', '00', '00', '01', '80', '04', '46']\n"
     ]
    }
   ],
   "source": [
    "print([ binascii.hexlify(x) for x in base64.b64decode(orig_X_train[0])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hex_X_train[0:4] [['00' '00' 'ed' '8c' '00' '32' 'c1' '7f' '00' '0c' '3d' '20' '00' '00'\n",
      "  'c0' '09' '00' '00' 'ec' '0b' '00' '32' 'ec' '0c' '00' '28' 'fd' '80'\n",
      "  '02' '10' '3d' '20' '00' '00' 'c0' '09' '00' '00' 'ff' '8c' '00' '00'\n",
      "  '40' '9d' '00' '0c' 'c0' '1f' '00' '08' '48' '00' '00' '10' 'c1' '9f'\n",
      "  '00' '08' 'c0' '1f' '00' '0c' 'ec' '0c']\n",
      " ['00' '06' 'ff' 'ff' 'ff' 'ff' '00' '00' '00' '00' '00' '03' '6c' '6c'\n",
      "  '78' '0a' '00' '20' '00' '98' '0b' '00' 'a9' '11' 'c0' '20' '00' '98'\n",
      "  '1b' '90' '90' 'f5' 'a0' '99' '20' 'c0' '20' '00' '99' '08' 'c0' '20'\n",
      "  '00' '98' '2b' 'c0' '20' '00' '99' '08' 'c1' '00' '00' 'd1' '00' '00'\n",
      "  'a1' '00' '00' '81' '00' '00' 'e0' '08']\n",
      " ['8c' '89' '00' '18' '8d' '4b' '00' '00' '8d' '69' '00' '00' '01' '28'\n",
      "  '48' '24' 'ad' '69' '00' '00' '8c' '49' '00' '20' '25' '29' '00' '01'\n",
      "  '10' '00' 'ff' 'f1' 'ac' '49' '00' '20' '8d' '42' '00' '00' 'af' 'a2'\n",
      "  '00' '18' '8c' 'c2' '00' '08' '00' '00' '30' '21' '8c' '42' '00' '00'\n",
      "  'ac' 'a2' '00' '0c' '3c' '02' '00' '00']\n",
      " ['58' '30' '30' '00' '50' '30' '10' '00' 'a7' '48' '00' '00' '58' '30'\n",
      "  'd1' 'e2' '50' '40' '10' '00' '58' '40' 'd1' 'de' '50' '40' '10' '00'\n",
      "  '58' '40' '30' '00' '50' '40' '10' '00' '58' '40' '30' '04' '50' '40'\n",
      "  '10' '00' '58' '40' 'd1' 'da' '58' '30' '30' '08' '50' '30' '10' '00'\n",
      "  '58' '30' '40' '00' '50' '30' '10' '00']] \n",
      "\n",
      "train_misfits[0:4] [] \n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "hex_X_train, train_misfits = etl.hex_data(orig_X_train)\n",
    "hex_X_dev, dev_misfits = etl.hex_data(orig_X_dev)\n",
    "hex_X_test, test_misfits = etl.hex_data(orig_X_test)\n",
    "\n",
    "print('hex_X_train[0:4]', hex_X_train[0:4], '\\n')\n",
    "print('train_misfits[0:4]', train_misfits[0:4], '\\n')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_X_test_stride2, test_misfits_stride_2 = etl.hex_data(orig_X_test, stride=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['9109', '0000', '9169', '0000', '810a', '0038', '9109', '0000',\n",
       "       'a10a', '003d', 'a14a', '003f', '9089', '0000', '9109', '0000',\n",
       "       '9149', '0000', '4cc6', '3182', '4800', '0001', '8001', '0014',\n",
       "       '3860', '0000', '3821', '0010', '7c08', '03a6', '4e80', '0020'],\n",
       "      dtype='|S4')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hex_X_test_stride2[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hexdoc_X_train = map(\"\".join, hex_X_train)\n",
    "hexdoc_X_test =  map(\"\".join, hex_X_test)\n",
    "hexdoc_X_dev = map(\"\".join, hex_X_dev)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_vecs(X, num_indices):\n",
    "    \"\"\"\n",
    "    sample the representation of two vecs over first num_indices of vector\n",
    "    \"\"\"\n",
    "    for feature_0, freq_0, feature_1, freq_1 in zip(v.inverse_transform(X)[0][0:num_indices], \n",
    "                                                    X.A[0][0:num_indices],\n",
    "                                                    v.inverse_transform(X)[1][0:num_indices], \n",
    "                                                    X.A[1][0:num_indices],\n",
    "                                                   ):\n",
    "        print(feature_0, freq_0, \"   \", feature_1, freq_1)\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "00 0c ec 0c 0     00 00 e0 08 3\n",
      "1f 00 0c ec 0     81 00 00 e0 2\n",
      "c0 1f 00 0c 0     00 81 00 00 0\n",
      "08 c0 1f 00 0     00 00 81 00 0\n",
      "00 08 c0 1f 0     a1 00 00 81 1\n",
      "9f 00 08 c0 0     00 a1 00 00 0\n",
      "c1 9f 00 08 0     00 00 a1 00 0\n",
      "48 00 00 10 0     d1 00 00 a1 0\n",
      "08 48 00 00 0     00 d1 00 00 0\n",
      "00 08 48 00 0     00 00 d1 00 0\n",
      "1f 00 08 48 0     c1 00 00 d1 0\n",
      "c0 1f 00 08 0     08 c1 00 00 0\n",
      "0c c0 1f 00 0     99 08 c1 00 0\n",
      "00 0c c0 1f 0     00 99 08 c1 0\n",
      "9d 00 0c c0 0     08 c0 20 00 0\n",
      "40 9d 00 0c 0     99 08 c0 20 0\n",
      "00 40 9d 00 0     00 99 08 c0 0\n",
      "00 00 40 9d 0     20 00 99 08 0\n",
      "8c 00 00 40 0     c0 20 00 99 0\n",
      "ff 8c 00 00 0     20 c0 20 00 0\n",
      "00 ff 8c 00 0     c0 20 00 98 0\n",
      "00 00 ff 8c 0     11 c0 20 00 0\n",
      "09 00 00 ff 0     6c 78 0a 00 0\n",
      "10 3d 20 00 0     6c 6c 78 0a 0\n",
      "02 10 3d 20 0     00 00 03 6c 0\n",
      "80 02 10 3d 0     00 00 00 03 0\n",
      "fd 80 02 10 0     00 00 00 00 0\n",
      "32 ec 0c 00 0     ff 00 00 00 0\n",
      "00 32 ec 0c 0     ff ff 00 00 0\n",
      "0b 00 32 ec 0     ff ff ff 00 0\n",
      "ec 0b 00 32 0     ff ff ff ff 0\n",
      "00 ec 0b 00 0     06 ff ff ff 0\n",
      "00 00 ec 0b 0     00 06 ff ff 0\n",
      "09 00 00 ec 0     00 e0 08 0\n",
      "c0 09 00 00 0     00 00 e0 0\n",
      "00 c0 09 00 0     81 00 00 0\n",
      "00 00 c0 09 0     00 81 00 0\n",
      "20 00 00 c0 0     00 00 81 0\n",
      "3d 20 00 00 0     a1 00 00 0\n",
      "0c 3d 20 00 0     00 a1 00 0\n",
      "00 0c 3d 20 0     00 00 a1 0\n",
      "7f 00 0c 3d 0     d1 00 00 0\n",
      "c1 7f 00 0c 0     00 d1 00 0\n",
      "32 c1 7f 00 0     00 00 d1 0\n",
      "00 32 c1 7f 0     c1 00 00 0\n",
      "8c 00 32 c1 0     08 c1 00 0\n",
      "ed 8c 00 32 0     99 08 c1 0\n",
      "00 ed 8c 00 0     08 c0 20 0\n",
      "00 00 ed 8c 0     99 08 c0 0\n",
      "0c ec 0c 0     00 99 08 0\n"
     ]
    }
   ],
   "source": [
    "compare_vecs(X_cv, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  (0, 0)\t26\n",
      "  (0, 1)\t16\n",
      "  (0, 2)\t10\n",
      "  (0, 3)\t5\n",
      "  (0, 27)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 41)\t1\n",
      "  (0, 115)\t1\n",
      "  (0, 119)\t1\n",
      "  (0, 253)\t1\n",
      "  (0, 274)\t1\n",
      "  (0, 538)\t1\n",
      "  (0, 589)\t1\n",
      "  (0, 601)\t1\n",
      "  (0, 739)\t1\n",
      "  (0, 745)\t1\n",
      "  (0, 1379)\t1\n",
      "  (0, 1381)\t1\n",
      "  (0, 1408)\t1\n",
      "  (0, 2600)\t2\n",
      "  (0, 2617)\t1\n",
      "  (0, 2752)\t1\n",
      "  (0, 3983)\t1\n",
      "  (0, 4016)\t1\n",
      "  (0, 4017)\t1\n",
      "  :\t:\n",
      "  (1, 71260)\t1\n",
      "  (1, 71261)\t1\n",
      "  (1, 71334)\t1\n",
      "  (1, 71335)\t1\n",
      "  (1, 72874)\t2\n",
      "  (1, 72875)\t2\n",
      "  (1, 72876)\t2\n",
      "  (1, 73663)\t1\n",
      "  (1, 73672)\t1\n",
      "  (1, 73825)\t1\n",
      "  (1, 74036)\t1\n",
      "  (1, 74062)\t1\n",
      "  (1, 74674)\t4\n",
      "  (1, 74896)\t3\n",
      "  (1, 74897)\t3\n",
      "  (1, 74904)\t1\n",
      "  (1, 74906)\t1\n",
      "  (1, 74920)\t1\n",
      "  (1, 84968)\t1\n",
      "  (1, 85326)\t1\n",
      "  (1, 85493)\t1\n",
      "  (1, 85516)\t1\n",
      "  (1, 85785)\t1\n",
      "  (1, 86074)\t1\n",
      "  (1, 87628)\t1\n",
      "  (0, 0)\t26\n",
      "  (0, 1)\t16\n",
      "  (0, 2)\t10\n",
      "  (0, 3)\t5\n",
      "  (0, 27)\t1\n",
      "  (0, 35)\t1\n",
      "  (0, 41)\t1\n",
      "  (0, 115)\t1\n",
      "  (0, 119)\t1\n",
      "  (0, 253)\t1\n",
      "  (0, 274)\t1\n",
      "  (0, 538)\t1\n",
      "  (0, 589)\t1\n",
      "  (0, 601)\t1\n",
      "  (0, 739)\t1\n",
      "  (0, 745)\t1\n",
      "  (0, 1379)\t1\n",
      "  (0, 1381)\t1\n",
      "  (0, 1408)\t1\n",
      "  (0, 2600)\t2\n",
      "  (0, 2617)\t1\n",
      "  (0, 2752)\t1\n",
      "  (0, 3983)\t1\n",
      "  (0, 4016)\t1\n",
      "  (0, 4017)\t1\n",
      "  :\t:\n",
      "  (1, 71260)\t1\n",
      "  (1, 71261)\t1\n",
      "  (1, 71334)\t1\n",
      "  (1, 71335)\t1\n",
      "  (1, 72874)\t2\n",
      "  (1, 72875)\t2\n",
      "  (1, 72876)\t2\n",
      "  (1, 73663)\t1\n",
      "  (1, 73672)\t1\n",
      "  (1, 73825)\t1\n",
      "  (1, 74036)\t1\n",
      "  (1, 74062)\t1\n",
      "  (1, 74674)\t4\n",
      "  (1, 74896)\t3\n",
      "  (1, 74897)\t3\n",
      "  (1, 74904)\t1\n",
      "  (1, 74906)\t1\n",
      "  (1, 74920)\t1\n",
      "  (1, 84968)\t1\n",
      "  (1, 85326)\t1\n",
      "  (1, 85493)\t1\n",
      "  (1, 85516)\t1\n",
      "  (1, 85785)\t1\n",
      "  (1, 86074)\t1\n",
      "  (1, 87628)\t1\n"
     ]
    }
   ],
   "source": [
    "bow_transform2 = v.transform(hexdoc_X_train[0:2])\n",
    "print(bow_transform2)\n",
    "print(bow_transform2[0:2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "#from IPython.core.debugger import set_trace\n",
    "\n",
    "vec_opts = {\n",
    "    \"ngram_range\": (1, 4),  # allow n-grams of 1-4 words in length (32-bits)\n",
    "    \"analyzer\": \"word\",     # analyze hex words\n",
    "    \"token_pattern\": \"..\",  # treat two characters as a word (e.g. 4b)\n",
    "    \"min_df\": 2,          # for demo purposes, be very selective about features\n",
    "    \"max_df\": .7\n",
    "}\n",
    "v = CountVectorizer(**vec_opts)\n",
    "X_cv = v.fit_transform(hexdoc_X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'42 00 20', 16814), (u'30 8d', 15044), (u'30 8c', 15039), (u'30 8a', 15038), (u'00 a7 2a', 4425), (u'08 d0 4b', 8089), (u'08 d0 4d', 8091), (u'bd 27 00 00', 26929), (u'3b 2c 4c', 15859), (u'fd 24 00 00', 31702)]\n",
      "32618\n"
     ]
    }
   ],
   "source": [
    "print(v.vocabulary_.items()[0:10])\n",
    "print(len(v.vocabulary_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "268515\n",
      "<class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "print(len(X_cv.indices))\n",
    "print(type(X_cv))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2048, 32618)\n"
     ]
    }
   ],
   "source": [
    "Xd = X_cv.todense()\n",
    "print(Xd.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[3 2 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "32618 32618\n"
     ]
    }
   ],
   "source": [
    "print(Xd.A[1][0:280])\n",
    "print(Xd.A[2][0:280])\n",
    "print(len(Xd.A[1]), len(Xd.A[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2048, 32618)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    }
   ],
   "source": [
    "print(X_cv.A[1][1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "idf_opts = {\"use_idf\": True}\n",
    "idf = TfidfTransformer(**idf_opts)\n",
    "\n",
    "# perform the idf transform\n",
    "X_idf = idf.fit_transform(X_cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2048x32618 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 268515 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "mnbClassifier = MultinomialNB(alpha=.01)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnb_model = mnbClassifier.fit(X_idf, np.array(orig_Y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.9, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_class2 = MultinomialNB(alpha=.9)\n",
    "mnb_m2 = mnb_class2.fit(X_idf, np.array(orig_Y_train))\n",
    "mnb_m2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(12, 32618)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_m2.coef_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0 0 0 ..., 0 0 0] 32618\n"
     ]
    }
   ],
   "source": [
    "diff = mnb_m2.coef_.argmax(axis=0) - mnb_model.coef_.argmax(axis=0)\n",
    "print(diff, len(diff))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([  119,   122,   145,   348,   508,   638,   678,   706,   732,\n",
      "         735,   811,   980,  1057,  1140,  1257,  1259,  1365,  1663,\n",
      "        1829,  1908,  2036,  2083,  2112,  2170,  2185,  2225,  2228,\n",
      "        2270,  2288,  2306,  2485,  2543,  2611,  2947,  3047,  3227,\n",
      "        3382,  3447,  3580,  3648,  3679,  3881,  4532,  4840,  5220,\n",
      "        5231,  5376,  5377,  5443,  5444,  5500,  5723,  5819,  6005,\n",
      "        6143,  6391,  6440,  6635,  6648,  6676,  6822,  6823,  7318,\n",
      "        7635,  7639,  7672,  7915,  8403,  8550,  8587,  8915,  8943,\n",
      "        8993,  9445,  9547,  9599,  9985, 10065, 10411, 10412, 10432,\n",
      "       10508, 10780, 10848, 11003, 11091, 11156, 11912, 12988, 13343,\n",
      "       13385, 13395, 13396, 13523, 13541, 13575, 13644, 13652, 13836,\n",
      "       13895, 14227, 14254, 14268, 14283, 14375, 14389, 14400, 14590,\n",
      "       15026, 15070, 15196, 15650, 15653, 15687, 15688, 15840, 15882,\n",
      "       15937, 15938, 15982, 16146, 16231, 16466, 16922, 17016, 17290,\n",
      "       17486, 17501, 17527, 17688, 18017, 18090, 18378, 18411, 18704,\n",
      "       19131, 19172, 19387, 19402, 19935, 19979, 19985, 20262, 20344,\n",
      "       20742, 20876, 20877, 20927, 21458, 21459, 21641, 21716, 21843,\n",
      "       22086, 22194, 22236, 22493, 22497, 22581, 22582, 22589, 22661,\n",
      "       22739, 22877, 22966, 23033, 23043, 23143, 23376, 23586, 23643,\n",
      "       23902, 23903, 23980, 23994, 24057, 24155, 24467, 24483, 24816,\n",
      "       24936, 25023, 25073, 25114, 25125, 25559, 25823, 25935, 26168,\n",
      "       26480, 26825, 26885, 27223, 27278, 27300, 27331, 27361, 27396,\n",
      "       28206, 28390, 28498, 28716, 28911, 29081, 29329, 29692, 29730,\n",
      "       30257, 30319, 30320, 30648, 30737, 30823, 31234, 31302, 31451,\n",
      "       31501, 31697, 31714, 31723, 31863, 31909, 31977, 32122, 32158,\n",
      "       32189, 32200, 32222, 32346, 32527]),) 230\n"
     ]
    }
   ],
   "source": [
    "print(diff.nonzero(), len(diff.nonzero()[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1])"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array([[1,2,3], [3,4,5]]).argmax(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.78816702,  0.15874927],\n",
       "       [ 0.99573485,  0.67326485],\n",
       "       [ 0.30202746,  0.08254132],\n",
       "       [ 0.17074652,  0.23769081],\n",
       "       [ 0.58169284,  0.89623799]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### fraction of \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -1.43609427e-01,  -1.43091363e-01,  -1.23641583e-01, ...,\n",
       "          2.15780009e+00,   2.15780009e+00,  -7.42260677e-02],\n",
       "       [ -1.52737588e-01,  -1.51384156e-01,   3.88255060e-05, ...,\n",
       "          2.14736399e+00,   2.14736399e+00,  -1.19542527e-01],\n",
       "       [ -1.20021201e-01,   2.11932672e+00,   2.11932672e+00, ...,\n",
       "          2.11932672e+00,   2.11932672e+00,   2.11932672e+00],\n",
       "       ..., \n",
       "       [ -1.65670445e-01,  -1.44586141e-01,  -1.45224101e-01, ...,\n",
       "          2.13577858e+00,   2.13577858e+00,   2.13577858e+00],\n",
       "       [ -1.46388702e-01,  -1.46248894e-01,  -1.38590454e-01, ...,\n",
       "          2.15596414e+00,   2.15596414e+00,  -1.40172263e-01],\n",
       "       [ -1.50320225e-01,  -1.45531084e-01,   2.14856712e+00, ...,\n",
       "          2.14856712e+00,   2.14856712e+00,  -1.43953078e-01]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model.coef_ - mnb_m2.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ -5.65005987,  -6.01492261,  -8.52966459, ..., -12.29128362,\n",
       "        -12.29128362,  -9.71026516],\n",
       "       [ -6.33280976,  -6.7671353 , -10.39285075, ..., -12.2267706 ,\n",
       "        -12.2267706 ,  -8.98114002],\n",
       "       [ -9.3873931 , -12.07434756, -12.07434756, ..., -12.07434756,\n",
       "        -12.07434756, -12.07434756],\n",
       "       ..., \n",
       "       [ -5.48503144,  -8.44794896,  -8.41913596, ..., -12.16042398,\n",
       "        -12.16042398, -12.16042398],\n",
       "       [ -4.01714529,  -4.48830593,  -7.55641829, ..., -12.2795785 ,\n",
       "        -12.2795785 ,  -7.33783876],\n",
       "       [ -6.73744773,  -7.56585362, -12.23396578, ..., -12.23396578,\n",
       "        -12.23396578,  -7.73559688]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model.coef_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ -4.51747173e+01  -4.16894052e+01  -1.80662927e+01 ...,   1.49495869e+01\n",
      "    1.49495869e+01  -6.34685816e+00]\n",
      " [ -3.95257515e+01  -3.54849225e+01   2.07833167e-03 ...,   1.45365664e+01\n",
      "    1.45365664e+01  -1.36503864e+01]\n",
      " [ -9.70584006e+00   1.35350022e+01   1.35350022e+01 ...,   1.35350022e+01\n",
      "    1.35350022e+01   1.35350022e+01]\n",
      " ..., \n",
      " [ -4.88267772e+01  -1.92930002e+01  -1.95923378e+01 ...,   1.41050451e+01\n",
      "    1.41050451e+01   1.41050451e+01]\n",
      " [ -6.59797211e+01  -5.87544761e+01  -2.76647139e+01 ...,   1.48751313e+01\n",
      "    1.48751313e+01  -2.97248897e+01]\n",
      " [ -3.56898976e+01  -2.78660683e+01   1.45829523e+01 ...,   1.45829523e+01\n",
      "    1.45829523e+01  -2.62092706e+01]]\n"
     ]
    }
   ],
   "source": [
    "delta = (mnb_model.coef_ - mnb_m2.coef_)*100.0 /mnb_model.coef_\n",
    "print(delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11.194846000324119"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "delta.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultinomialNB(alpha=0.01, class_prior=None, fit_prior=True)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnb_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_predictions = mnb_model.predict(X_idf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['avr', 'alphaev56', 'arm', 'm68k', 'mips', 'mipsel', 'powerpc', 's390', 'sh4', 'sparc', 'x86_64', 'xtensa']\n"
     ]
    }
   ],
   "source": [
    "print(etl.SUPPORTED_ARCHITECTURES)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([u'powerpc', u'xtensa', u'mips', u's390', u's390', u'alphaev56',\n",
       "       u'alphaev56', u'x86_64', u'powerpc', u'mips'],\n",
       "      dtype='<U9')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_predictions[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'alphaev56', u'arm', u'avr', u'm68k', u'mips', u'mipsel', u'powerpc', u's390', u'sh4', u'sparc', u'x86_64', u'xtensa']\n"
     ]
    }
   ],
   "source": [
    "print(mnb_model.classes_.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Y_train[0:4] \n",
      " [[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]] \n",
      "\n",
      "allowed_Y_train[0:4] \n",
      " [[1 1 0 0 0 0 1 1 1 0 0 1]\n",
      " [1 0 1 0 0 1 1 0 1 0 0 1]\n",
      " [0 0 1 1 1 0 1 0 1 1 0 0]\n",
      " [0 1 1 1 1 1 0 1 0 0 0 0]] \n",
      "\n",
      "['00' '00' 'ed' '8c' '00' '32' 'c1' '7f' '00' '0c' '3d' '20' '00' '00' 'c0'\n",
      " '09' '00' '00' 'ec' '0b' '00' '32' 'ec' '0c' '00' '28' 'fd' '80' '02' '10'\n",
      " '3d' '20' '00' '00' 'c0' '09' '00' '00' 'ff' '8c' '00' '00' '40' '9d' '00'\n",
      " '0c' 'c0' '1f' '00' '08' '48' '00' '00' '10' 'c1' '9f' '00' '08' 'c0' '1f'\n",
      " '00' '0c' 'ec' '0c']\n",
      "['0000ed8c0032c17f000c3d200000c0090000ec0b0032ec0c0028fd8002103d200000c0090000ff8c0000409d000cc01f000848000010c19f0008c01f000cec0c', '0006ffffffff0000000000036c6c780a002000980b00a911c02000981b9090f5a09920c020009908c02000982bc020009908c10000d10000a10000810000e008']\n",
      "['00 00 ed 8c 00 32 c1 7f 00 0c 3d 20 00 00 c0 09 00 00 ec 0b 00 32 ec 0c 00 28 fd 80 02 10 3d 20 00 00 c0 09 00 00 ff 8c 00 00 40 9d 00 0c c0 1f 00 08 48 00 00 10 c1 9f 00 08 c0 1f 00 0c ec 0c', '00 06 ff ff ff ff 00 00 00 00 00 03 6c 6c 78 0a 00 20 00 98 0b 00 a9 11 c0 20 00 98 1b 90 90 f5 a0 99 20 c0 20 00 99 08 c0 20 00 98 2b c0 20 00 99 08 c1 00 00 d1 00 00 a1 00 00 81 00 00 e0 08']\n",
      "128\n"
     ]
    }
   ],
   "source": [
    "\n",
    "Y_train, allowed_Y_train = class_to_ones_hot(orig_Y_train, orig_train_targets, mnb_model.classes_.tolist())\n",
    "Y_dev, allowed_Y_dev = class_to_ones_hot(orig_Y_dev, orig_dev_targets, mnb_model.classes_.tolist())\n",
    "Y_test, allowed_Y_test = class_to_ones_hot(orig_Y_test, orig_test_targets, mnb_model.classes_.tolist())\n",
    "\n",
    "print('Y_train[0:4]', '\\n', Y_train[0:4], '\\n')\n",
    "print('allowed_Y_train[0:4]', '\\n', allowed_Y_train[0:4], '\\n')\n",
    "print(hex_X_train[0])\n",
    "print(map(\"\".join, hex_X_train[0:2]))\n",
    "print(map(\" \".join, hex_X_train[0:2]))\n",
    "print(len(map(\"\".join, [hex_X_train[0]])[0]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "raw probs\n",
      "[[  3.95378015e-16   2.37632598e-15   2.39473240e-15   4.89321789e-15\n",
      "    2.13349722e-15   2.55725879e-14   1.00000000e+00   5.49013143e-15\n",
      "    4.80712870e-15   4.08227072e-15   1.47239899e-15   7.91660446e-14]\n",
      " [  1.72830322e-17   3.02696647e-16   8.74247472e-18   2.32475725e-15\n",
      "    7.59035168e-17   1.15949590e-17   3.20994269e-15   3.71650269e-16\n",
      "    1.78774921e-16   5.77322918e-17   1.49534581e-16   1.00000000e+00]\n",
      " [  2.22521023e-15   4.51549638e-15   2.47002444e-15   2.00395398e-14\n",
      "    1.00000000e+00   9.55206016e-13   1.65454600e-13   2.76210222e-14\n",
      "    4.78126814e-14   6.84727854e-16   8.60855130e-15   3.57770739e-14]\n",
      " [  3.26558414e-15   7.67673832e-14   1.46144655e-15   3.60330698e-14\n",
      "    1.82243572e-15   1.56065544e-14   3.89855363e-16   1.00000000e+00\n",
      "    1.37067205e-15   5.60524901e-16   3.39215386e-16   3.69157015e-15]]\n",
      "allowed probs\n",
      "[[  3.95378015e-16   2.37632598e-15   0.00000000e+00   0.00000000e+00\n",
      "    0.00000000e+00   0.00000000e+00   1.00000000e+00   5.49013143e-15\n",
      "    4.80712870e-15   0.00000000e+00   0.00000000e+00   7.91660446e-14]\n",
      " [  1.72830322e-17   0.00000000e+00   8.74247472e-18   0.00000000e+00\n",
      "    0.00000000e+00   1.15949590e-17   3.20994269e-15   0.00000000e+00\n",
      "    1.78774921e-16   0.00000000e+00   0.00000000e+00   1.00000000e+00]]\n",
      "allowed\n",
      "[[1 1 0 0 0 0 1 1 1 0 0 1]\n",
      " [1 0 1 0 0 1 1 0 1 0 0 1]]\n",
      "[ 6 11]\n",
      "[u'powerpc', u'xtensa', u'mips', u's390', u's390', u'alphaev56', u'alphaev56', u'x86_64', u'powerpc', u'mips']\n",
      "correct\n",
      "[u'powerpc', u'xtensa', u'mips', u's390', u's390', u'alphaev56', u'alphaev56', u'x86_64', u'powerpc', u'mips']\n",
      "[[0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 0 1]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 1 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [1 0 0 0 0 0 0 0 0 0 0 0]\n",
      " [0 0 0 0 0 0 0 0 0 0 1 0]\n",
      " [0 0 0 0 0 0 1 0 0 0 0 0]\n",
      " [0 0 0 0 1 0 0 0 0 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "probs_train = mnb_model.predict_proba(X_idf)\n",
    "print(\"raw probs\")\n",
    "print(probs_train[0:4])\n",
    "print(\"allowed probs\")\n",
    "print(probs_train[0:2]*allowed_Y_train[0:2])\n",
    "print(\"allowed\")\n",
    "print(allowed_Y_train[0:2])\n",
    "print(np.argmax(probs_train[0:2]*allowed_Y_train[0:2], axis=1))\n",
    "print(map(mnb_model.classes_.tolist().__getitem__, np.argmax(probs_train[0:10]*allowed_Y_train[0:10], axis=1)))\n",
    "print(\"correct\")\n",
    "print(orig_Y_train[0:10])\n",
    "print(Y_train[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def guess_from_target(probs, allowed_Y, supported_architectures, ones_hot=True):\n",
    "    \"\"\"\n",
    "    Improve our chances by taking the max over the possible targets (6 instead of 12)\n",
    "    probs: numerical array of shape (m, n_classes)\n",
    "    targets: ones-hot array of shape (m, n_classes)\n",
    "    \n",
    "    returns: (m, 1) of the most likely ISA arch names after discards or\n",
    "             (m, n_classes) one-hot representation of best guess\n",
    "    \"\"\"\n",
    "    if ones_hot:\n",
    "        result = np.zeros(probs.shape)\n",
    "        result[np.argmax(probs*allowed_Y, axis=1)] = 1\n",
    "        return \n",
    "    return map(supported_architectures.__getitem__, np.argmax(probs*allowed_Y, axis=1))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2048 2048\n",
      "[  3.95378015e-16   2.37632598e-15   2.39473240e-15   4.89321789e-15\n",
      "   2.13349722e-15   2.55725879e-14   1.00000000e+00   5.49013143e-15\n",
      "   4.80712870e-15   4.08227072e-15   1.47239899e-15   7.91660446e-14] [1 1 0 0 0 0 1 1 1 0 0 1] [u'alphaev56', u'arm', u'powerpc', u's390', u'sh4', u'xtensa']\n"
     ]
    }
   ],
   "source": [
    "print(len(probs_train), len(allowed_Y_train))\n",
    "print(probs_train[0], allowed_Y_train[0], orig_train_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 11,  4, ...,  6,  4,  6])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(probs_train*allowed_Y_train, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = guess_from_target(probs_train, allowed_Y_train, mnb_model.classes_.tolist(), ones_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(u'powerpc', u'powerpc')"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[0], orig_Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>2048</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m68k</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>192</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           0\n",
       "count   2048\n",
       "unique    12\n",
       "top     m68k\n",
       "freq     192"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "D = pd.DataFrame(predictions)\n",
    "D.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = pd.Series(orig_Y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "powerpc      192\n",
       "m68k         191\n",
       "x86_64       188\n",
       "xtensa       184\n",
       "sh4          182\n",
       "mips         177\n",
       "arm          168\n",
       "alphaev56    167\n",
       "sparc        151\n",
       "mipsel       150\n",
       "s390         150\n",
       "avr          148\n",
       "dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have a pretty good distribution of classes < 10% variance in counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def describe_results(predictions, orig_Y):\n",
    "    wrong = []\n",
    "    for i in range(len(predictions)):\n",
    "        if predictions[i] != orig_Y[i]:\n",
    "            wrong.append([predictions[i], orig_Y[i]])\n",
    "    print('training error: {}%'.format(100.0*len(wrong)/len(predictions)))\n",
    "    print('some mistakes')\n",
    "    print(wrong[0:15])\n",
    "    return wrong"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.048828125%\n",
      "some mistakes\n",
      "[[u'm68k', u'xtensa']]\n"
     ]
    }
   ],
   "source": [
    "wrong = describe_results(predictions,orig_Y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2048x32618 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 268515 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdw = pd.DataFrame(wrong)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pdw.columns = ['incorrect', 'correct']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>m68k</td>\n",
       "      <td>xtensa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       incorrect correct\n",
       "count          1       1\n",
       "unique         1       1\n",
       "top         m68k  xtensa\n",
       "freq           1       1"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">incorrect</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>correct</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>xtensa</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>m68k</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        incorrect                  \n",
       "            count unique   top freq\n",
       "correct                            \n",
       "xtensa          1      1  m68k    1"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw.groupby(by=pdw.correct).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model is worst at predicting sh4, then arm, m68k, xtensa\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"4\" halign=\"left\">correct</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>unique</th>\n",
       "      <th>top</th>\n",
       "      <th>freq</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>incorrect</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>m68k</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>xtensa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          correct                    \n",
       "            count unique     top freq\n",
       "incorrect                            \n",
       "m68k            1      1  xtensa    1"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw.groupby(by=pdw.incorrect).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m68k</td>\n",
       "      <td>xtensa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incorrect correct\n",
       "0      m68k  xtensa"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most false positives come from x86_64 and m68k, we are slightly over-fitting to them\n",
    "pdw[pdw.incorrect == 'm68k'][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m68k</td>\n",
       "      <td>xtensa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  incorrect correct\n",
       "0      m68k  xtensa"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>incorrect</th>\n",
       "      <th>correct</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [incorrect, correct]\n",
       "Index: []"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pdw[pdw.correct == 'sparc']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# repeat for dev dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "pipeline = Pipeline([\n",
    "    ('vec',   CountVectorizer(**vec_opts)),\n",
    "    ('idf',  TfidfTransformer(**idf_opts))\n",
    "    #('mnb_classifier',MultinomialNB())\n",
    "])\n",
    "\n",
    "X_dev_idf = pipeline.fit_transform(hexdoc_X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_cv_dev = v.transform(hex_X_dev, lowercase=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "vec_opts = {\n",
    "    \"ngram_range\": (1, 4),  # allow n-grams of 1-4 words in length (32-bits)\n",
    "    \"analyzer\": \"word\",     # analyze hex words\n",
    "    \"token_pattern\": \"..\",  # treat two characters as a word (e.g. 4b)\n",
    "    \"min_df\": 3,          # \n",
    "    \"vocabulary\": v.vocabulary_\n",
    "}\n",
    "v_dev = CountVectorizer(**vec_opts)\n",
    "X_cv_dev = v_dev.fit_transform(hexdoc_X_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "idf_dev = TfidfTransformer(**idf_opts)\n",
    "\n",
    "# perform the idf transform\n",
    "X_idf_dev = idf.fit_transform(X_cv_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_idf_dev = idf.transform(X_cv_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1792x456942 sparse matrix of type '<type 'numpy.int64'>'\n",
       "\twith 267835 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 276,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cv_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2816x197698 sparse matrix of type '<type 'numpy.float64'>'\n",
       "\twith 411843 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_idf_dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'X_cv_dev' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-cad0c745cbbb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mX_cv_dev\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'X_cv_dev' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2816 2816\n",
      "[  6.64878586e-27   5.54827445e-27   6.76160444e-27   7.68025984e-26\n",
      "   3.44199010e-25   8.20187998e-27   1.00000000e+00   1.27719061e-28\n",
      "   2.06622779e-26   1.05862086e-25   6.68052332e-26   5.57266354e-23] [1 0 1 1 1 0 1 0 0 0 0 1] [u'alphaev56', u'avr', u'm68k', u'mips', u'powerpc', u'xtensa']\n"
     ]
    }
   ],
   "source": [
    "probs_dev = mnb_model.predict_proba(X_idf_dev)\n",
    "\n",
    "print(len(probs_dev), len(allowed_Y_dev))\n",
    "print(probs_dev[0], allowed_Y_dev[0], orig_dev_targets[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_dev = guess_from_target(probs_dev, allowed_Y_dev, mnb_model.classes_.tolist(), ones_hot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training error: 0.390625%\n",
      "some mistakes\n",
      "[[u'x86_64', u'sh4'], [u'x86_64', u'arm'], [u'm68k', u'powerpc'], [u'x86_64', u'xtensa'], [u'xtensa', u's390'], [u'x86_64', u'm68k'], [u'm68k', u'xtensa'], [u'alphaev56', u'mipsel'], [u'mips', u'm68k'], [u'sh4', u'mipsel'], [u'm68k', u'xtensa']]\n"
     ]
    }
   ],
   "source": [
    "wrong = describe_results(predictions_dev, orig_Y_dev)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# end dev"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[7 0 4]\n",
      " [0 0 4]]\n",
      "[0 2]\n",
      "[[ 0.  0.  0.]\n",
      " [ 0.  0.  0.]]\n"
     ]
    },
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for axis 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-159-b2f79fb71f76>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0md\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for axis 0 with size 2"
     ]
    }
   ],
   "source": [
    "a = np.array([[7,2,4],[2,0,4]])\n",
    "b = np.array([[1,0,1], [0,0,1]])\n",
    "c = a*b\n",
    "print(c)\n",
    "d = np.zeros(c.shape)\n",
    "print(np.argmax(c, axis=1))\n",
    "print(d)\n",
    "d[np.argmax(c, axis=1)] = 1\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4])"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(c, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([7, 4])"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[ c >= np.max(c, axis=1, keepdims=1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 2]\n",
      " [2 1]]\n",
      "[[ 1 -1]\n",
      " [-1  1]]\n",
      "[[ 1 -2]\n",
      " [-2  1]]\n",
      "[[ 1 -2]\n",
      " [-2  1]]\n"
     ]
    }
   ],
   "source": [
    "a = np.array([[1,2], [2, 1]])\n",
    "b = np.array([[1,-1], [-1, 1]])\n",
    "print(a)\n",
    "print(b)\n",
    "print(a*b)\n",
    "print(np.multiply(a,b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_decomposition/pls_.py:83: UserWarning: Maximum number of iterations reached\n",
      "  warnings.warn('Maximum number of iterations reached')\n",
      "/usr/local/lib/python2.7/dist-packages/sklearn/cross_decomposition/pls_.py:293: UserWarning: Y residual constant at iteration 11\n",
      "  warnings.warn('Y residual constant at iteration %s' % k)\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "bad input shape (12, 4096)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mValueError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-49-70ddcd13f8df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0mX_arr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m \u001b[0mplot_subfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"With unlabeled samples + CCA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"cca\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m \u001b[0mplot_subfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_arr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"With unlabeled samples + PCA\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pca\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-49-70ddcd13f8df>\u001b[0m in \u001b[0;36mplot_subfigure\u001b[0;34m(X, Y, subplot, title, transform)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mclassif\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mSVC\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'linear'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m     \u001b[0mclassif\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtranspose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msubplot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/svm/base.pyc\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m    149\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_sparse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msparse\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcallable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkernel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 151\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'C'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    152\u001b[0m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcheck_X_y\u001b[0;34m(X, y, accept_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, warn_on_dtype, estimator)\u001b[0m\n\u001b[1;32m    524\u001b[0m                         dtype=None)\n\u001b[1;32m    525\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 526\u001b[0;31m         \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcolumn_or_1d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwarn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    527\u001b[0m         \u001b[0m_assert_all_finite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    528\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_numeric\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkind\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'O'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python2.7/dist-packages/sklearn/utils/validation.pyc\u001b[0m in \u001b[0;36mcolumn_or_1d\u001b[0;34m(y, warn)\u001b[0m\n\u001b[1;32m    560\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    561\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 562\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bad input shape {0}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    564\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: bad input shape (12, 4096)"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.datasets import make_multilabel_classification\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cross_decomposition import CCA\n",
    "\n",
    "\n",
    "def plot_hyperplane(clf, min_x, max_x, linestyle, label):\n",
    "    # get the separating hyperplane\n",
    "    w = clf.coef_[0]\n",
    "    a = -w[0] / w[1]\n",
    "    xx = np.linspace(min_x - 5, max_x + 5)  # make sure the line is long enough\n",
    "    yy = a * xx - (clf.intercept_[0]) / w[1]\n",
    "    plt.plot(xx, yy, linestyle, label=label)\n",
    "\n",
    "\n",
    "def plot_subfigure(X, Y, subplot, title, transform):\n",
    "    if transform == \"pca\":\n",
    "        X = PCA(n_components=12).fit_transform(X)\n",
    "    elif transform == \"cca\":\n",
    "        X = CCA(n_components=12).fit(X, Y_train).transform(X)\n",
    "    else:\n",
    "        raise ValueError\n",
    "\n",
    "    min_x = np.min(X[:, 0])\n",
    "    max_x = np.max(X[:, 0])\n",
    "\n",
    "    min_y = np.min(X[:, 1])\n",
    "    max_y = np.max(X[:, 1])\n",
    "\n",
    "    classif = SVC(kernel='linear')\n",
    "    classif.fit(X, Y_train.transpose())\n",
    "\n",
    "    plt.subplot(2, 2, subplot)\n",
    "    plt.title(title)\n",
    "\n",
    "    zero_class = np.where(Y_train[:, 0])\n",
    "    one_class = np.where(Y_train[:, 1])\n",
    "    plt.scatter(X[:, 0], X[:, 1], s=40, c='gray', edgecolors=(0, 0, 0))\n",
    "    plt.scatter(X[zero_class, 0], X[zero_class, 1], s=160, edgecolors='b',\n",
    "                facecolors='none', linewidths=2, label='Class 1')\n",
    "    plt.scatter(X[one_class, 0], X[one_class, 1], s=80, edgecolors='orange',\n",
    "                facecolors='none', linewidths=2, label='Class 2')\n",
    "\n",
    "    plot_hyperplane(classif.estimators_[0], min_x, max_x, 'k--',\n",
    "                    'Boundary\\nfor class 1')\n",
    "    plot_hyperplane(classif.estimators_[1], min_x, max_x, 'k-.',\n",
    "                    'Boundary\\nfor class 2')\n",
    "    plt.xticks(())\n",
    "    plt.yticks(())\n",
    "\n",
    "    plt.xlim(min_x - .5 * max_x, max_x + .5 * max_x)\n",
    "    plt.ylim(min_y - .5 * max_y, max_y + .5 * max_y)\n",
    "    if subplot == 2:\n",
    "        plt.xlabel('First principal component')\n",
    "        plt.ylabel('Second principal component')\n",
    "        plt.legend(loc=\"upper left\")\n",
    "\n",
    "\n",
    "plt.figure(figsize=(8, 6))\n",
    "\n",
    "# X, Y = make_multilabel_classification(n_classes=2, n_labels=1,\n",
    "#                                       allow_unlabeled=True,\n",
    "#                                       random_state=1)\n",
    "X_arr = X.toarray()\n",
    "\n",
    "plot_subfigure(X_arr, Y_train, 1, \"With unlabeled samples + CCA\", \"cca\")\n",
    "plot_subfigure(X_arr, Y, 2, \"With unlabeled samples + PCA\", \"pca\")\n",
    "\n",
    "# X, Y = make_multilabel_classification(n_classes=2, n_labels=1,\n",
    "#                                       allow_unlabeled=False,\n",
    "#                                       random_state=1)\n",
    "\n",
    "# plot_subfigure(X, Y, 3, \"Without unlabeled samples + CCA\", \"cca\")\n",
    "# plot_subfigure(X, Y, 4, \"Without unlabeled samples + PCA\", \"pca\")\n",
    "\n",
    "plt.subplots_adjust(.04, .02, .97, .94, .09, .2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Xt, Yt = make_multilabel_classification(n_classes=12, n_labels=1,\n",
    "                                      allow_unlabeled=True,\n",
    "                                      random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0],\n",
       "       [0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Yt[0:2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 20) (100, 12)\n"
     ]
    }
   ],
   "source": [
    "print(Xt.shape, Yt.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(100, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [1, 0],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1],\n",
       "       [1, 1]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print Y.shape\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
